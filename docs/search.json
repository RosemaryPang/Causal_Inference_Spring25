[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome Page",
    "section": "",
    "text": "Welcome to DACSS790 Causal Inference. All classroom material, including recordings, slides, tutorials, and assignment descriptions, will be posted in Canvas.\nThis tutorial website contains the R code and output of weekly tutorials.\n Weekly Tutorials \nWeek 1 Regression Review & Bias\nWeek 2 Directed Acyclic Graphs\nWeek 3 Randomization Design\nWeek 4 Mediation Analysis\nWeek 5 Instrumental Variable\nWeek 6 Panel Data Analysis\nWeek 7 Difference in Differences\nWeek 8 Matching"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Tutorial1.html",
    "href": "Tutorial1.html",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "",
    "text": "In this tutorial, you’ll learn (or refresh your memory) about hypothesis testing, ordinary least squares (OLS) regression, transformation, logistic regression, and we’ll discuss why we can’t make causal statement by simply adding control variables to our model.\nBy the end of this tutorial, you should be familiar with the following:\n1. Basic concepts of hypothesis testing\n2. OLS regression: single and multiple linear regression, regression with interaction term\n3. Transformation\n4. Logistic regression"
  },
  {
    "objectID": "Tutorial1.html#example",
    "href": "Tutorial1.html#example",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Example",
    "text": "Example\nA manufacturer says the battery of their laptop lasts 10 hours on average. We want to test whether this is true (\\(\\mu = 10\\)). Because we are interested in deviations from 10 in either direction, this is a two-sided test. Now we have a sample, with sample mean (\\(\\bar{x}\\)) = 9.04, sample standard deviation (\\({s}\\)) = 1.83, and sample size = 30. Can we reject the null hypothesis?\nWe first calculate t-value based on sample statistics:\n\\[t=\\frac{\\bar{x} - \\mu_0}{{s}/{\\sqrt{n}}}=\\frac{9.04-10}{1.83/{\\sqrt{30}}}=-2.87\\]\nWe then need to find the critical value base on our \\(\\alpha\\)-level. Let’s set \\(\\alpha=0.05\\). Since the absolute value of t-value is greater than the critical value, we can reject the null hypothesis.\n\ncritical &lt;- round(qt(0.975,df=(30-1)),2)\ncritical\n\n[1] 2.05\n\n\nWe can manually calculate the p-value. With a p-value smaller than 0.05 (the \\(\\alpha\\)-level), we can also reject the null hypothesis.\n\nt_statistic &lt;- 2.87\np_value &lt;- (1 - pt(t_statistic, df= 29)) * 2\np_value\n\n[1] 0.00758546"
  },
  {
    "objectID": "Tutorial1.html#simple-linear-regression",
    "href": "Tutorial1.html#simple-linear-regression",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression\nTo start, let’s consider the simplest case—a single independent variable predicting an outcome. This is known as simple linear regression, where we model a straight-line relationship between the predictor and the response variable. We will walk through an example using student.survey data.\n\ndata(student.survey)\nhead(student.survey)\n\n  subj ge ag  hi  co   dh   dr tv sp ne ah    ve pa           pi           re\n1    1  m 32 2.2 3.5    0  5.0  3  5  0  0 FALSE  r conservative   most weeks\n2    2  f 23 2.1 3.5 1200  0.3 15  7  5  6 FALSE  d      liberal occasionally\n3    3  f 27 3.3 3.0 1300  1.5  0  4  3  0 FALSE  d      liberal   most weeks\n4    4  f 35 3.5 3.2 1500  8.0  5  5  6  3 FALSE  i     moderate occasionally\n5    5  m 23 3.1 3.5 1600 10.0  6  6  3  0 FALSE  i very liberal        never\n6    6  m 39 3.5 3.5  350  3.0  4  5  7  0 FALSE  d      liberal occasionally\n     ab    aa    ld\n1 FALSE FALSE FALSE\n2 FALSE FALSE    NA\n3 FALSE FALSE    NA\n4 FALSE FALSE FALSE\n5 FALSE FALSE FALSE\n6 FALSE FALSE    NA\n\nstudent.survey$male &lt;- ifelse(student.survey$ge == \"m\", 1, 0)\n\nThis data is from smss package. It consists of responses of graduate students in the social sciences enrolled in STA 6126 in a recent term at the University of Florida. Variables in this data include gender (ge), high school GPA (hi), average number of hours per week that you watch TV (tv), and political affiliation (pa). We start by looking into the relationship between watching TV and high school GPA.\n\nggplot(data = student.survey, aes(x = tv, y = hi)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(x = \"Hours of TV Watched per Week\", \n       y = \"GPA\", \n       title = \"Relationship Between TV Watching and GPA\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe visualization tells us there’s a negative relationship between watching TV and GPA. We can use OLS regression to test whether this relationship is statistically significant.\n\nm1 &lt;- lm(hi~tv, data=student.survey)\nsummary(m1)\n\n\nCall:\nlm(formula = hi ~ tv, data = student.survey)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.2583 -0.2456  0.0417  0.3368  0.7051 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.441353   0.085345  40.323   &lt;2e-16 ***\ntv          -0.018305   0.008658  -2.114   0.0388 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4467 on 58 degrees of freedom\nMultiple R-squared:  0.07156,   Adjusted R-squared:  0.05555 \nF-statistic: 4.471 on 1 and 58 DF,  p-value: 0.03879\n\n\nFrom the OLS regression results, we can model the relationship between hours watching TV and high school GPA: \\(hi=3.441−0.0183*tv\\). When a student watches 0 hours of TV, their predicted GPA is 3.441. Each additional hour of TV watched per week is associated with a decrease of 0.018 points in the GPA, and the impact is statistically significant at the 95% confidence level."
  },
  {
    "objectID": "Tutorial1.html#multiple-linear-regression",
    "href": "Tutorial1.html#multiple-linear-regression",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nIn reality, most outcomes are influenced by more than one factor. Simple linear regression is often too simplistic to capture complex relationships. Multiple linear regression extends the model by including multiple independent variables, allowing us to control for additional factors and better isolate the effect of each predictor. Let’s explore how this works with the same data.\n\nm2 &lt;- lm(hi~tv+male+pa,data=student.survey)\nsummary(m2)\n\n\nCall:\nlm(formula = hi ~ tv + male + pa, data = student.survey)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.11908 -0.25376  0.02283  0.31597  0.68353 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.428977   0.133216  25.740   &lt;2e-16 ***\ntv          -0.017175   0.009004  -1.907   0.0617 .  \nmale        -0.138154   0.117482  -1.176   0.2447    \npai          0.161780   0.134692   1.201   0.2349    \npar          0.024887   0.153392   0.162   0.8717    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.446 on 55 degrees of freedom\nMultiple R-squared:  0.1223,    Adjusted R-squared:  0.0585 \nF-statistic: 1.917 on 4 and 55 DF,  p-value: 0.1206\n\n\nResults show that after controlling for gender and party affiliation, hours of TV watching still has a statistically significant impact on GPA at the 90% confidence level. Each additional hour of TV watched per week is associated with a 0.017 point decrease in GPA. Compared to Democrats, Independents have a 0.16 point higher GPA, but this difference is not statistically significant.\nIn this model, we use Democrats as the reference category (baseline) for party affiliation. You can also change the baseline into other category using relevel() function.\n\nstudent.survey$pa2 &lt;- relevel(student.survey$pa, ref = \"i\")\n\nIf we set Independents as the baseline category for party affiliation, how does being Republican affect high school GPA compared to Independents?"
  },
  {
    "objectID": "Tutorial1.html#interaction-term",
    "href": "Tutorial1.html#interaction-term",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Interaction Term",
    "text": "Interaction Term\nSo far, we have assumed that each independent variable has an independent and additive effect on the dependent variable. However, in many cases, the effect of one variable depends on the level of another. This is where interaction terms come in. By including interaction terms in our regression model, we can capture how the relationship between one variable and the outcome changes depending on another variable.\n\nm3 &lt;- lm(hi~tv*male, data=student.survey)\nsummary(m3)\n\n\nCall:\nlm(formula = hi ~ tv * male, data = student.survey)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.18709 -0.23932  0.07162  0.30540  0.74298 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.539245   0.130413  27.139   &lt;2e-16 ***\ntv          -0.021885   0.012852  -1.703   0.0941 .  \nmale        -0.177346   0.173034  -1.025   0.3098    \ntv:male      0.004405   0.017531   0.251   0.8025    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4482 on 56 degrees of freedom\nMultiple R-squared:  0.09761,   Adjusted R-squared:  0.04926 \nF-statistic: 2.019 on 3 and 56 DF,  p-value: 0.1216\n\n\nIn this model, \\(GPA=3.539−0.0219TV−0.1773Male+0.0044(TV*Male)\\). Unlike previous models where we could interpret coefficients directly, interaction terms modify the effect of one variable depending on the value of another. This means we need to substitute specific values to understand the impact on different groups. For female students (male=0), watching one additional hour of TV is associated with a 0.0219 point decrease in GPA. For male students (male=1), each additional hour of TV is associated with a 0.0175 point (\\(-0.219+0.044\\)) decrease in GPA. Since the interaction term is not statistically significant, it suggests that the relationship between TV watching and GPA is similar for both genders."
  },
  {
    "objectID": "Tutorial1.html#regression-table",
    "href": "Tutorial1.html#regression-table",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Regression Table",
    "text": "Regression Table\nTo present the results of the three regression models (m1, m2, and m3) side by side in a well-formatted table, you can use the stargazer package in R.\n\nstargazer(m1, m2, m3, type = \"text\",\n          title = \"Regression Results\",\n          dep.var.labels = \"High School GPA\",\n          covariate.labels = c(\"TV Hours\", \"Male\", \"Party Affiliation: Independent\", \"Party Affiliation: Republican\", \"TV Hours x Male\"),\n          omit.stat = c(\"f\", \"ser\"),\n          no.space = TRUE)\n\n\nRegression Results\n============================================================\n                                    Dependent variable:     \n                               -----------------------------\n                                      High School GPA       \n                                  (1)       (2)       (3)   \n------------------------------------------------------------\nTV Hours                       -0.018**   -0.017*   -0.022* \n                                (0.009)   (0.009)   (0.013) \nMale                                      -0.138    -0.177  \n                                          (0.117)   (0.173) \nParty Affiliation: Independent             0.162            \n                                          (0.135)           \nParty Affiliation: Republican              0.025            \n                                          (0.153)           \nTV Hours x Male                                      0.004  \n                                                    (0.018) \nConstant                       3.441***  3.429***  3.539*** \n                                (0.085)   (0.133)   (0.130) \n------------------------------------------------------------\nObservations                      60        60        60    \nR2                               0.072     0.122     0.098  \nAdjusted R2                      0.056     0.059     0.049  \n============================================================\nNote:                            *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "Tutorial1.html#simpsons-paradox-and-collider-bias",
    "href": "Tutorial1.html#simpsons-paradox-and-collider-bias",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Simpson’s Paradox and Collider Bias",
    "text": "Simpson’s Paradox and Collider Bias\nSimpson’s paradox means that a tend appears in different groups of data, but disappears or reverses when these groups are combined. Collider bias occurs when we condition on (control for, subset by, or select a sample based on) a variable that is influenced by two other variables. Let’s look into an example using simulated data.\n\nset.seed(123)\n\nn &lt;- 500  \n\n# Generate exercise levels (hours per week)\nexercise &lt;- rnorm(n, mean = 5, sd = 2)\n\n# Generate blood pressure - Randomly generated, NO relationship with exercise\nblood_pressure &lt;- rnorm(n, mean = 120, sd = 5)\n\n# Obesity is influenced by both exercise and blood pressure (collider)\nobesity &lt;- ifelse(exercise &lt; 5 | blood_pressure &gt; 120, 1, 0)\n\n# Modify Blood Pressure to create group-specific effects\nblood_pressure[obesity == 0] &lt;- blood_pressure[obesity == 0] - 2 * exercise[obesity == 0]  # Exercise LOWERS BP for non-obese\nblood_pressure[obesity == 1] &lt;- blood_pressure[obesity == 1] + 2 * exercise[obesity == 1]  # Exercise RAISES BP for obese\n\n# Create dataframe\ndata &lt;- data.frame(exercise, blood_pressure, obesity)\n\nThe visualization below shows an example of Simpson’s Paradox: the trend differs when analyzing separate groups compared to the pooled data.\n\nggplot(data, aes(x = exercise, y = blood_pressure, color = as.factor(obesity))) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_smooth(aes(color = \"Pooled Data\"), method = \"lm\", se = FALSE, data = data, linetype = \"dashed\") +\n  labs(title = \"Simpson's Paradox: Exercise & Blood Pressure with Obesity as Collider\",\n       x = \"Exercise (hours per week)\",\n       y = \"Blood Pressure (mmHg)\",\n       color = \"Obesity Status\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIn our case, obesity is a collider because it is influenced by both exercise and blood pressure. Let’s examine the regression results by running models on the pooled data, within each obesity group separately, and with obesity as a control variable.\n\n# Overall regression (ignoring obesity)\noverall &lt;- lm(blood_pressure ~ exercise, data = data)\n\n# Regression within subgroup\nobese &lt;- lm(blood_pressure ~ exercise, data = data %&gt;% filter(obesity == 1))\nnon_obese &lt;- lm(blood_pressure ~ exercise, data = data %&gt;% filter(obesity == 0))\n\n# Controlling for obesity\ncontrol &lt;- lm(blood_pressure ~ exercise + obesity, data = data)\n\nstargazer(overall, obese, non_obese, control,\n          type = \"text\")\n\n\n=======================================================================================================================\n                                                            Dependent variable:                                        \n                    ---------------------------------------------------------------------------------------------------\n                                                              blood_pressure                                           \n                              (1)                     (2)                      (3)                      (4)            \n-----------------------------------------------------------------------------------------------------------------------\nexercise                   -1.593***                2.819***                -1.997***                 2.048***         \n                            (0.314)                 (0.128)                  (0.211)                  (0.135)          \n                                                                                                                       \nobesity                                                                                              32.395***         \n                                                                                                      (0.586)          \n                                                                                                                       \nConstant                  130.907***               117.935***              115.721***                88.997***         \n                            (1.705)                 (0.619)                  (1.422)                  (0.991)          \n                                                                                                                       \n-----------------------------------------------------------------------------------------------------------------------\nObservations                  500                     362                      138                      500            \nR2                           0.049                   0.575                    0.396                    0.867           \nAdjusted R2                  0.047                   0.573                    0.392                    0.866           \nResidual Std. Error    13.651 (df = 498)        4.443 (df = 360)        3.206 (df = 136)          5.112 (df = 497)     \nF Statistic         25.717*** (df = 1; 498) 486.228*** (df = 1; 360) 89.334*** (df = 1; 136) 1,618.847*** (df = 2; 497)\n=======================================================================================================================\nNote:                                                                                       *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nIn Model 1, we see that exercise has a negative impact on blood pressure, which makes sense. However, when we examine different subgroups, we find that the direction of the effect varies across groups—a classic example of Simpson’s Paradox. Surprisingly, in Model 4, after controlling for obesity, the coefficient for exercise flips from negative to positive. Does this mean that exercising regularly increases blood pressure? Of course not. This misleading result occurs because obesity is a collider, and controlling for a collider introduces bias rather than reducing it."
  },
  {
    "objectID": "Tutorial1.html#multicollinearity",
    "href": "Tutorial1.html#multicollinearity",
    "title": "Tutorial 1 Regression Review & Bias",
    "section": "Multicollinearity",
    "text": "Multicollinearity\nAdding too many control variables can lead to multicollinearity, where some predictors become highly correlated with each other. This makes it difficult to determine the independent effect of each variable, leading to unstable estimates and inflated standard errors. As a result, even if a variable has a real effect, its coefficient may appear insignificant due to the overlap in explanatory power with other controls. Let’s look into the example below.\nIn this example, we have 100 employee with employees’ ages range from 25 to 65. Everyone in the company graduated college at the age of 22, and started working there. Everyone is paid roughly based on their experience. If we run regression using both age and experience as independent variables, we have multicollinearity problem.\n\nset.seed(123)\nage &lt;- sample(25:65, size  = 100, replace = TRUE)\nexperience &lt;- age - 22\nsalary &lt;- 2000 * (experience) + rnorm(100, sd = 20000)\n\nsummary(lm(salary ~ age + experience))\n\n\nCall:\nlm(formula = salary ~ age + experience)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-40598 -12992   -983  11339  65231 \n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -41856.8     8607.8  -4.863 4.41e-06 ***\nage           1943.2      181.7  10.694  &lt; 2e-16 ***\nexperience        NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19630 on 98 degrees of freedom\nMultiple R-squared:  0.5385,    Adjusted R-squared:  0.5338 \nF-statistic: 114.4 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\nThis situation is easy to detect because R completely omits the coefficient for experience, indicating perfect multicollinearity. However, in real-world cases, variables may be highly correlated but not perfectly related, meaning R will still report a coefficient. For example, let’s add some variation to age.\n\nage &lt;- age + round(rnorm(100)) \nsummary(lm(salary ~ age + experience))\n\n\nCall:\nlm(formula = salary ~ age + experience)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-40591 -12986   -992  11336  65225 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   757.713  45204.994   0.017    0.987\nage             6.244   2049.783   0.003    0.998\nexperience   1936.977   2066.586   0.937    0.351\n\nResidual standard error: 19740 on 97 degrees of freedom\nMultiple R-squared:  0.5385,    Adjusted R-squared:  0.529 \nF-statistic: 56.59 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nNow, we see that although R reports coefficients for both variables, the results are quite strange. The standard errors are extremely high. The p-values are large, meaning we fail to detect a significant relationship – even though age and experience should clearly influence salary. However, the F-test p-value is still small, suggesting that at least one of the predictors matters – we just can’t tell which one!\nThis demonstrates two key indicators of multicollinearity: 1. Large standard errors (high uncertainty in estimates). 2. High p-values for individual variables, despite a significant overall model (low F-test p-value).\nMulticollinearity makes estimates unreliable, leading to misleading or biased results. So, be cautious when adding too many highly correlated control variables—sometimes, they do more harm than good!"
  },
  {
    "objectID": "Tutorial2.html",
    "href": "Tutorial2.html",
    "title": "Tutorial 2 Directed Acyclic Graphs",
    "section": "",
    "text": "Directed Acyclic Graphs (DAGs) help us visualize causal relationships between variables. In this tutorial, you’ll learn about creating DAGs in R. By the end of this tutorial, you should be familiar with the following:\n1. packages ggdag and dagitty\n2. Create a simple DAG\n3. Customize DAG with colors, and labels\n4. Highlight causal paths, confounders, and colliders"
  },
  {
    "objectID": "Tutorial2.html#finding-paths",
    "href": "Tutorial2.html#finding-paths",
    "title": "Tutorial 2 Directed Acyclic Graphs",
    "section": "Finding paths",
    "text": "Finding paths\nggdag_paths() function shows all the causal and non-causal paths between the exposure and outcome, including frontdoor paths, backdoor paths and paths involving colliders.\n\nggdag_paths(winelife)"
  },
  {
    "objectID": "Tutorial2.html#finding-parents",
    "href": "Tutorial2.html#finding-parents",
    "title": "Tutorial 2 Directed Acyclic Graphs",
    "section": "Finding parents",
    "text": "Finding parents\nThe ggdag_parents() function identifies and visualizes the parent nodes of a selected variable in a DAG. Identifying parent nodes can help identify potential backdoor paths if the selected node is the exposure in a DAG.\n\nggdag_parents(winelife_label, \"Wine\", text=F, use_labels = \"label\")"
  },
  {
    "objectID": "Tutorial2.html#closing-the-backdoor",
    "href": "Tutorial2.html#closing-the-backdoor",
    "title": "Tutorial 2 Directed Acyclic Graphs",
    "section": "Closing the backdoor",
    "text": "Closing the backdoor\nThe backdoor criterion says that we have sufficient set of variables to control for confounding when it blocks all backdoor paths from treatment to the outcome, and when it does not include any descendants of treatment. Using ggdag_adjustment_set() function, we can quickly get the minimally sufficient adjustment sets to adjust for when analyzing the effect of x on y.\n\nggdag_adjustment_set(winelife_label,text=F,use_labels = \"label\")\n\n\n\n\n\n\n\n\nLet’s see another practice using the example on Lecture Slide page 23.\n\n# First make the DAG\nPractice &lt;- dagify(\n  Y ~ V + A + M,\n  A ~ Z + W,\n  M ~ W,\n  W ~ Z,\n  Z ~ V,\n  exposure = \"A\",\n  outcome = \"Y\"\n)\n\nggdag(Practice, layout=\"stress\")\n\n\n\n\n\n\n\nggdag_adjustment_set(Practice)"
  },
  {
    "objectID": "Tutorial2.html#control-for-collider",
    "href": "Tutorial2.html#control-for-collider",
    "title": "Tutorial 2 Directed Acyclic Graphs",
    "section": "Control for collider?",
    "text": "Control for collider?\nIn the lecture, we emphasized that we should never control/block a collider. Because doing so induces a fake correlation between its parent variables, even if they were originally independent.\nTo formally analyze whether variables are conditionally independent (d-separated) or conditionally related (d-connected) in a DAG, we can use the function ggdag_dseparated().\n\n# First create a DAG with a collider\nIncomeHealth &lt;- dagify(\n  Wine ~ Income + Health,\n  exposure = \"Income\",\n  outcome = \"Health\"\n)\n\nggdag(IncomeHealth, layout='tree')\n\n\n\n\n\n\n\nggdag_dseparated(IncomeHealth)\n\n\n\n\n\n\n\n\nWe see that Health and Income are d-separated, meaning they are independent. Let’s see what happens if we control for the collider.\n\nggdag_dseparated(IncomeHealth,\n  controlling_for = \"Wine\")\n\n\n\n\n\n\n\n\nNow we see after controlling the collider, Health and Income become d-connected, meaning we are creating a fake relationship between them."
  },
  {
    "objectID": "Tutorial2.html#blocking-the-frontdoor",
    "href": "Tutorial2.html#blocking-the-frontdoor",
    "title": "Tutorial 2 Directed Acyclic Graphs",
    "section": "Blocking the frontdoor?",
    "text": "Blocking the frontdoor?\nFrontdoor adjustment leverages the mediator as a tool to estimate the causal effect of X on Y. It does not simply ‘control for’ or ‘block’ the mediator in the same way we adjust for confounder. We will discuss frontdoor adjustment in more detail during the Mediation Analysis week. For now, let’s explore what happens when we block the mediator.\n\n# First create a DAG with a mediator\nwinedrug &lt;- dagify(\n  Lifespan ~ Drug,\n  Drug ~ Wine,\n  exposure = \"Wine\",\n  outcome = \"Lifespan\"\n)\n\nggdag(winedrug, layout='stress')\n\n\n\n\n\n\n\nggdag_dseparated(winedrug)\n\n\n\n\n\n\n\nggdag_dseparated(winedrug, controlling_for = \"Drug\")"
  },
  {
    "objectID": "Tutorial3.html",
    "href": "Tutorial3.html",
    "title": "Tutorial 3 Randomization Design",
    "section": "",
    "text": "Randomization is a fundamental principle in experimental design that helps ensure unbiased causal inference. In this tutorial, you’ll learn how to implement different randomization techniques in R using the randomizr package. By the end of this tutorial, you should be familiar with the following:\n1. packages randomizr\n2. Simple random assignment\n3. Complete random assignment\n4. Block random assignment\n5. Clustered assignment\n6. Blocked and clustered assignment\n\nFront-end Matters\nrandomizr is a lightweight R package designed to simplify the random assignment process in experiments. It provides a transparent, flexible, and reproducible way to assign units to treatment and control groups using various randomization designs. Proper randomization is essential for ensuring valid causal inference, but in many studies, the details of how treatment was assigned are often lost or imprecisely documented. randomizr helps researchers generate, document, and replicate random assignments with ease, reducing errors and improving experimental rigor.\n\n#install.packages(\"randomizr\")\n\nlibrary(randomizr)\n\n\n\nSimulating data for demonstration\nWe’ll simulate a dataset of 600 individuals, each with attributes such as FavoriteFruit, PreferredDrink, and AgeGroup. Additionally, we’ll introduce Region to represent clustering and DietType to represent blocks.\n\nset.seed(123)  \n\nN &lt;- 600\n\n# Simulate attributes\nFavoriteFruit &lt;- sample(c(\"Apple\", \"Banana\", \"Cherry\", \"Orange\"), N, replace = TRUE)\nPreferredDrink &lt;- sample(c(\"Water\", \"Juice\", \"Soda\", \"Tea\"), N, replace = TRUE)\nAgeGroup &lt;- sample(c(\"Child\", \"Teen\", \"Adult\", \"Senior\"), N, replace = TRUE)\n\n# Simulate clusters (Regions)\nRegion &lt;- sample(paste(\"Region\", 1:6), N, replace = TRUE)\n\n# Simulate blocks (Diet Types)\nDietType &lt;- sample(c(\"Vegetarian\", \"Vegan\", \"Keto\", \"Low-fat\"), N, replace = TRUE)\n\n# Combine into a data frame\nsimulated_data &lt;- data.frame(\n  FavoriteFruit,\n  PreferredDrink,\n  AgeGroup,\n  Region,\n  DietType\n)\n\n# Display the first few rows of the dataset\nhead(simulated_data)\n\n  FavoriteFruit PreferredDrink AgeGroup   Region   DietType\n1        Cherry            Tea    Child Region 2 Vegetarian\n2        Cherry          Juice   Senior Region 2    Low-fat\n3        Cherry            Tea     Teen Region 5      Vegan\n4        Banana          Water    Child Region 6    Low-fat\n5        Cherry           Soda    Child Region 5       Keto\n6        Banana           Soda    Child Region 4    Low-fat\n\n\nWe now need to create simulated potential outcomes. We’ll call the untreated outcome \\(Y0\\) and we’ll call the treated outcome \\(Y1\\). If we were really running an experiment, we would only observe either \\(Y0\\) or \\(Y1\\) for each subject, but since we are simulating, we generate both. Our inferential target is the average treatment effect (ATE), which is defined as the average difference between \\(Y0\\) and \\(Y1\\).\n\n# Convert categorical variables to factors\nsimulated_data$AgeGroup &lt;- factor(simulated_data$AgeGroup, levels = c(\"Child\", \"Teen\", \"Adult\", \"Senior\"))\nsimulated_data$DietType &lt;- factor(simulated_data$DietType, levels = c(\"Vegetarian\", \"Vegan\", \"Keto\", \"Low-fat\"))\n\n# Assign numerical values to AgeGroup and DietType for outcome calculation\nage_effect &lt;- as.numeric(simulated_data$AgeGroup)\ndiet_effect &lt;- as.numeric(simulated_data$DietType)\n\n# Calculate potential outcomes\nset.seed(123)  # For reproducibility\nsimulated_data$Y0 &lt;- rnorm(N, mean = 10 + age_effect - diet_effect, sd = 3)\nsimulated_data$Y1 &lt;- simulated_data$Y0 + 2*age_effect + 3*diet_effect \n\n# Display the first few rows with outcomes\nhead(simulated_data)\n\n  FavoriteFruit PreferredDrink AgeGroup   Region   DietType        Y0       Y1\n1        Cherry            Tea    Child Region 2 Vegetarian  8.318573 13.31857\n2        Cherry          Juice   Senior Region 2    Low-fat  9.309468 29.30947\n3        Cherry            Tea     Teen Region 5      Vegan 14.676125 24.67612\n4        Banana          Water    Child Region 6    Low-fat  7.211525 21.21153\n5        Cherry           Soda    Child Region 5       Keto  8.387863 19.38786\n6        Banana           Soda    Child Region 4    Low-fat 12.145195 26.14519\n\n# Calculate true ATE\nATE_true &lt;- with(simulated_data, mean(Y1 - Y0))\nprint(ATE_true)\n\n[1] 12.41\n\n\nWe are now ready to allocate treatment assignments to subjects. Let’s start by contrasting simple and complete random assignment.\n\n\nSimple random assignment\nSimple random assignment assigns all subjects to treatment with an equal probability by flipping a (weighted) coin for each subject. The main trouble with simple random assignment is that a different number of subjects might be assigned to each group.\nsimple_ra() assumes a two-group design and a 0.50 probability of assignment. Note that if we don’t set seed, the number of subject in each group is subject to change.\n\nset.seed(123)\nZ &lt;- simple_ra(N=N)\ntable(Z)\n\nZ\n  0   1 \n310 290 \n\n\nWe can compare the ATE from the randomized experiment, and compare it with the true ATE.\n\n# Assign treatment and control groups based on random assignment\nsimulated_data2 &lt;- cbind(simulated_data,Z)\n\nY_observed &lt;- ifelse(simulated_data2$Z == 1, simulated_data2$Y1, simulated_data2$Y0)\n\nATE_est &lt;- mean(Y_observed[Z == 1]) - mean(Y_observed[Z == 0])\nprint(ATE_est)\n\n[1] 12.02648\n\n\nThis estimated ATE is pretty close to the true ATE (12.41). This suggests that this random sample is a good representation of the population.\nWe can also change the probability of assignment, by specifying the prob argument. prob indicates the percentage that receive the treatment.\n\nZ &lt;- simple_ra(N = N, prob = 0.30)\ntable(Z)\n\nZ\n  0   1 \n425 175 \n\n\nIs this still a good representation of the population?\n\n# Assign treatment and control groups based on random assignment\nsimulated_data2 &lt;- cbind(simulated_data,Z)\n\nY_observed &lt;- ifelse(simulated_data2$Z == 1, simulated_data2$Y1, simulated_data2$Y0)\n\nATE_est &lt;- mean(Y_observed[Z == 1]) - mean(Y_observed[Z == 0])\nprint(ATE_est)\n\n[1] 12.37752\n\n\nEven after changing the percentage of receiving treatment, it still suggests a good representation of the population.\nSimple random assignment ensures that the treatment and control groups are representative of the population, regardless of the percentage assigned to treatment.\n\n\nComplete random assignment\nComplete random assignment is very similar to simple random assignment, except that the researcher can specify exactly how many units are assigned to each condition.\nIf you only specify N, complete_ra() assigns exactly half of the subjects to treatment.\n\nZ &lt;- complete_ra(N = N)\ntable(Z)\n\nZ\n  0   1 \n300 300 \n\n\nTo change the number of units assigned, specify the m argument\n\nZ &lt;- complete_ra(N = N, m = 200)\ntable(Z)\n\nZ\n  0   1 \n400 200 \n\n\nIs Complete random assignment a good representation of the population?\n\n# Assign treatment and control groups based on random assignment\nsimulated_data2 &lt;- cbind(simulated_data,Z)\n\nY_observed &lt;- ifelse(simulated_data2$Z == 1, simulated_data2$Y1, simulated_data2$Y0)\n\nATE_est &lt;- mean(Y_observed[Z == 1]) - mean(Y_observed[Z == 0])\nprint(ATE_est)\n\n[1] 12.89898\n\n\nAgain, the estimated ATE is very close to the real ATE, which suggests a good representation of the population.\nWhen should you use simple_ra() versus complete_ra()? Basically, if the number of units is known beforehand, complete_ra() is always preferred, since researchers can plan exactly how many treatments will be deployed.\n\n\nBlock random assignment\nBlock random assignment, also known as stratified random assignment, is a powerful technique for improving the precision and interpretability of experimental results. In this design, subjects are first grouped into blocks based on pre-treatment characteristics, and then randomization occurs separately within each block. In our study, the blocking variable is Diet Type, which includes four categories: Vegetarian, Vegan, Omnivore, and Pescatarian. By blocking on diet type, we ensure that each dietary group has an approximately equal proportion of treated and control units, allowing for fair comparisons within each group. Blocking is particularly useful when we suspect that treatment effects may differ across diet types—for example, the treatment may have a stronger effect on one group than another.\nBlocking also enhances statistical precision when the blocking variable is correlated with the outcome. Since dietary habits may influence health-related outcomes, blocking on diet type helps reduce random variation and improves the accuracy of our treatment effect estimates.\nThe only required argument to block_ra() is blocks. Blocks can be a factor, character, or numeric variable. For example, when simulating data, we set DietType as a block.\n\nZ &lt;- block_ra(blocks = simulated_data$DietType)\ntable(Z, simulated_data$DietType)\n\n   \nZ   Vegetarian Vegan Keto Low-fat\n  0         84    60   82      74\n  1         85    60   81      74\n\n\nNow we see for each diet type, the subjects are devided equally into treatment and control group.\n\nZ &lt;- block_ra(N)\ntable(Z)\n\nZ\n0 \n1 \n\n\nIf we have multiple blocking variables – for example, DietType, FavoriteFruit, and PreferredDrink – we need to create a single composite blocking variable that uniquely identifies each combination of these three factors.\n\n# Create a composite block variable by pasting the three factors together\nsimulated_data$CompositeBlock &lt;- paste(simulated_data$DietType, simulated_data$FavoriteFruit, simulated_data$PreferredDrink, sep = \"_\")\n\n# Perform block random assignment using the composite block\nZ &lt;- block_ra(blocks = simulated_data$CompositeBlock)\n\n# Check treatment assignment within each block\nhead(table(Z, simulated_data$CompositeBlock))\n\n   \nZ   Keto_Apple_Juice Keto_Apple_Soda Keto_Apple_Tea Keto_Apple_Water\n  0                6               5              4                5\n  1                6               6              5                5\n   \nZ   Keto_Banana_Juice Keto_Banana_Soda Keto_Banana_Tea Keto_Banana_Water\n  0                 3                7               4                 8\n  1                 3                6               5                 9\n   \nZ   Keto_Cherry_Juice Keto_Cherry_Soda Keto_Cherry_Tea Keto_Cherry_Water\n  0                 4                6               3                 5\n  1                 5                6               3                 4\n   \nZ   Keto_Orange_Juice Keto_Orange_Soda Keto_Orange_Tea Keto_Orange_Water\n  0                 6                5               6                 3\n  1                 6                4               6                 4\n   \nZ   Low-fat_Apple_Juice Low-fat_Apple_Soda Low-fat_Apple_Tea\n  0                   4                  6                 4\n  1                   4                  6                 5\n   \nZ   Low-fat_Apple_Water Low-fat_Banana_Juice Low-fat_Banana_Soda\n  0                   4                    5                   5\n  1                   5                    5                   4\n   \nZ   Low-fat_Banana_Tea Low-fat_Banana_Water Low-fat_Cherry_Juice\n  0                  6                    5                    4\n  1                  5                    5                    4\n   \nZ   Low-fat_Cherry_Soda Low-fat_Cherry_Tea Low-fat_Cherry_Water\n  0                   7                  4                    3\n  1                   6                  5                    4\n   \nZ   Low-fat_Orange_Juice Low-fat_Orange_Soda Low-fat_Orange_Tea\n  0                    2                   6                  4\n  1                    2                   7                  4\n   \nZ   Low-fat_Orange_Water Vegan_Apple_Juice Vegan_Apple_Soda Vegan_Apple_Tea\n  0                    4                 2                5               5\n  1                    4                 3                5               6\n   \nZ   Vegan_Apple_Water Vegan_Banana_Juice Vegan_Banana_Soda Vegan_Banana_Tea\n  0                 3                  2                 4                3\n  1                 4                  2                 4                2\n   \nZ   Vegan_Banana_Water Vegan_Cherry_Juice Vegan_Cherry_Soda Vegan_Cherry_Tea\n  0                  2                  7                 3                4\n  1                  2                  6                 4                5\n   \nZ   Vegan_Cherry_Water Vegan_Orange_Juice Vegan_Orange_Soda Vegan_Orange_Tea\n  0                  4                  4                 3                4\n  1                  3                  5                 3                5\n   \nZ   Vegan_Orange_Water Vegetarian_Apple_Juice Vegetarian_Apple_Soda\n  0                  3                      5                     7\n  1                  3                      4                     6\n   \nZ   Vegetarian_Apple_Tea Vegetarian_Apple_Water Vegetarian_Banana_Juice\n  0                    6                      5                       5\n  1                    5                      5                       6\n   \nZ   Vegetarian_Banana_Soda Vegetarian_Banana_Tea Vegetarian_Banana_Water\n  0                      7                     8                       4\n  1                      6                     8                       5\n   \nZ   Vegetarian_Cherry_Juice Vegetarian_Cherry_Soda Vegetarian_Cherry_Tea\n  0                       6                      5                     6\n  1                       5                      4                     5\n   \nZ   Vegetarian_Cherry_Water Vegetarian_Orange_Juice Vegetarian_Orange_Soda\n  0                       4                       7                      4\n  1                       4                       6                      4\n   \nZ   Vegetarian_Orange_Tea Vegetarian_Orange_Water\n  0                     4                       5\n  1                     4                       4\n\n\nComparing the estimated ATE with the real ATE, it shows block random assignment is still representative of the population.\n\n# Assign treatment and control groups based on random assignment\nsimulated_data2 &lt;- cbind(simulated_data,Z)\n\nY_observed &lt;- ifelse(simulated_data2$Z == 1, simulated_data2$Y1, simulated_data2$Y0)\n\nATE_est &lt;- mean(Y_observed[Z == 1]) - mean(Y_observed[Z == 0])\nprint(ATE_est)\n\n[1] 12.4004\n\n\n\n\nClustered assignment\nClustered random assignment occurs when entire pre-existing groups (clusters) – rather than individuals – are assigned to treatment or control. This is sometimes unavoidable in experiments where treatment naturally occurs at the group level, such as assigning entire households, classrooms, or villages to an intervention.\nHowever, clustered assignment reduces the effective sample size, making it harder to detect treatment effects. If outcomes within a cluster are highly correlated (e.g., students in the same classroom perform similarly), the experiment effectively has fewer independent observations, reducing statistical power. In extreme cases, if outcomes are perfectly correlated within clusters, the experiment’s effective sample size is only equal to the number of clusters, not the number of individuals. Despite these drawbacks, clustered randomization remains necessary in many field experiments where individual-level randomization is impractical or could lead to contamination between treated and control units.\nIn R, clustered assignment can be implemented using the cluster_ra() function, ensuring that all units within a given cluster receive the same treatment while maintaining randomization integrity. For example, when simulating data, we set Region as a cluster.\n\nZ &lt;- cluster_ra(clusters = simulated_data$Region)\n\ntable(simulated_data$Region, Z)\n\n          Z\n             0   1\n  Region 1   0 111\n  Region 2   0  96\n  Region 3 113   0\n  Region 4  87   0\n  Region 5  88   0\n  Region 6   0 105\n\n\nThis shows that each cluster is either assigned to treatment or control. No two units within the same cluster are assigned to different conditions.\n\n\nBlocked and clustered assignment\nThe power of clustered experiments can sometimes be improved through blocking. In this scenario, whole clusters are members of a particular block – imagine villages nested within discrete regions, or classrooms nested within discrete schools.\nSince our data has Region to represent clustering and DietType to represent blocks, we can use block_and_cluster_ra() to conduct Blocked and clustered assignment.\n\n# Assign each Region to a single Diet Type (ensuring no overlap)\nregion_diet_mapping &lt;- aggregate(DietType ~ Region, data = simulated_data, FUN = function(x) unique(x)[1])\nsimulated_data &lt;- merge(simulated_data, region_diet_mapping, by = \"Region\", suffixes = c(\"\", \"_fixed\"))\nsimulated_data$DietType &lt;- simulated_data$DietType_fixed\nsimulated_data$DietType_fixed &lt;- NULL  # Remove extra column\n\nZ &lt;- block_and_cluster_ra(clusters = simulated_data$Region, blocks = simulated_data$DietType)\nhead(table(simulated_data$Region, Z))\n\n          Z\n             0   1\n  Region 1   0 111\n  Region 2  96   0\n  Region 3 113   0\n  Region 4  87   0\n  Region 5  88   0\n  Region 6   0 105\n\nhead(table(simulated_data$DietType, Z))\n\n            Z\n               0   1\n  Vegetarian  96   0\n  Vegan       88   0\n  Keto       113 111\n  Low-fat     87 105"
  },
  {
    "objectID": "Tutorial4.html",
    "href": "Tutorial4.html",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "",
    "text": "Mediation analysis is a key tool in causal inference, helping researchers understand how and why a treatment influences an outcome through an intermediate variable (mediator). In this tutorial, you’ll learn how to implement both traditional and causal mediation analysis in R using the mediation package, as well as explore structural equation modeling (SEM) with the lavaan package. By the end of this tutorial, you should be familiar with the following:\n1. packages mediation and lavaan\n2. Traditional mediation analysis\n3. Causal mediation analysis\n4. Structural equation modeling"
  },
  {
    "objectID": "Tutorial4.html#simple-model",
    "href": "Tutorial4.html#simple-model",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "Simple model",
    "text": "Simple model\n\nresults &lt;- mediate(step2, step3, treat='X', mediator='M',boot=TRUE, sims=500)\n\nRunning nonparametric bootstrap\n\nsummary(results)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME             0.3565       0.2178         0.52  &lt;2e-16 ***\nADE              0.0396      -0.1911         0.29   0.696    \nTotal Effect     0.3961       0.1624         0.66   0.004 ** \nProp. Mediated   0.9000       0.5019         2.01   0.004 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 100 \n\n\nSimulations: 500 \n\nplot(results)\n\n\n\n\n\n\n\n\nThe total effect in the summary is \\(b_1\\) in the fist step: total effect of X on Y without M. The direct effect (ADE) is \\(b_4\\) in the third step: a direct effect of X on Y after taking into account of a mediator effect of M. The mediation effect (ACME) is the total effect minus the direct effect (\\(b_1-b_4\\)), which equals to the product of a coefficient of X in the second step and a coefficient of M in the last step (\\(b_2*b_3\\)). The goal of mediation analysis is to obtain this mediation effect and see if it’s statistically significant.\nLet’s look into a more complicated model. We’re using job data in mediation package."
  },
  {
    "objectID": "Tutorial4.html#model-with-covariates",
    "href": "Tutorial4.html#model-with-covariates",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "Model with covariates",
    "text": "Model with covariates\nWe use the jobs data from mediation package. This dataset is from the Job Search Intervention Study. In this dataset, people in the treatment group participated in job-skills workshops (treat). The outcome variable is a continuous measure of depressive symptoms (depress2). A continuous measure of job-search self efficacy represents a key mediating variable (job_seek). And we also have a list of covariates, including pre-treatment level of depression (depress1), education (educ), income, race(nonwhite), marital status (marrital), age, sex, previous occupation (occp), and the level of economic hardship (econ_hard).\n\ndata(\"jobs\")\nhead(jobs)\n\n  treat econ_hard depress1 sex      age                    occp marital\n1     1      3.00     1.91   1 34.16712           professionals married\n2     1      3.67     1.36   0 26.10137 operatives/kindred wrks nevmarr\n3     1      4.00     2.09   1 35.02192 operatives/kindred wrks nevmarr\n4     0      2.33     1.45   0 27.48767              manegerial married\n5     1      1.33     1.73   1 31.61096        clerical/kindred separtd\n6     1      3.00     1.55   0 40.43835              manegerial married\n    nonwhite   educ income job_seek depress2  work1 comply control job_dich\n1 non.white1 gradwk   50k+ 4.833333 1.727273 psyemp      0   treat        1\n2     white0 somcol 15t24k 3.833333 2.000000 psyemp      0   treat        0\n3 non.white1 somcol 25t39k 4.500000 2.181818 psyump      0   treat        1\n4     white0   bach 25t39k 3.666667 1.545455 psyump      0 control        0\n5 non.white1 highsc 25t39k 2.500000 2.363636 psyump      1   treat        0\n6     white0 highsc   50k+ 4.000000 1.181818 psyump      1   treat        1\n  job_disc\n1        4\n2        3\n3        4\n4        3\n5        2\n6        3\n\n\nFor causal mediation analysis, we first estimate two linear regressions for both the mediator and the outcome.\n\nmodel.m &lt;- lm(job_seek ~ treat + depress1 + econ_hard + sex + age + occp + marital + nonwhite + educ + income, data = jobs)\n\nmodel.y &lt;- lm(depress2 ~ treat + job_seek + depress1 + econ_hard + sex + age + occp + marital + nonwhite + educ + income, data = jobs)\n\nout.1 &lt;- mediate(model.m, model.y, sims = 1000, boot = TRUE, treat = \"treat\",\nmediator = \"job_seek\")\n\nRunning nonparametric bootstrap\n\nsummary(out.1)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value  \nACME            -0.0137      -0.0321         0.00   0.078 .\nADE             -0.0368      -0.1189         0.04   0.360  \nTotal Effect    -0.0505      -0.1338         0.02   0.204  \nProp. Mediated   0.2718      -1.9019         3.35   0.254  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 899 \n\n\nSimulations: 1000 \n\n\nThe job-skills workshop reduces depressive symptoms, at least in part, by increasing job-seeking behavior."
  },
  {
    "objectID": "Tutorial4.html#sensitivity",
    "href": "Tutorial4.html#sensitivity",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "Sensitivity",
    "text": "Sensitivity\nWe can quickly run a sensitivity analysis using the medsens() function from the mediation package. This will help assess how unmeasured confounding between the mediator (job_seek) and outcome (depress2) could affect your results.\n\nsens.out &lt;- medsens(out.1, sims = 1000)\n\nsummary(sens.out)\n\n\nMediation Sensitivity Analysis for Average Causal Mediation Effect\n\nSensitivity Region\n\n       Rho    ACME 95% CI Lower 95% CI Upper R^2_M*R^2_Y* R^2_M~R^2_Y~\n [1,] -0.9  0.1183      -0.0274       0.2640         0.81       0.5293\n [2,] -0.8  0.0715      -0.0166       0.1597         0.64       0.4182\n [3,] -0.7  0.0489      -0.0115       0.1093         0.49       0.3202\n [4,] -0.6  0.0342      -0.0081       0.0766         0.36       0.2353\n [5,] -0.5  0.0232      -0.0057       0.0520         0.25       0.1634\n [6,] -0.4  0.0142      -0.0038       0.0321         0.16       0.1046\n [7,] -0.3  0.0064      -0.0025       0.0153         0.09       0.0588\n [8,] -0.2 -0.0007      -0.0049       0.0036         0.04       0.0261\n [9,] -0.1 -0.0073      -0.0172       0.0026         0.01       0.0065\n[10,]  0.0 -0.0137      -0.0312       0.0037         0.00       0.0000\n[11,]  0.1 -0.0202      -0.0453       0.0050         0.01       0.0065\n[12,]  0.2 -0.0268      -0.0600       0.0065         0.04       0.0261\n[13,]  0.3 -0.0338      -0.0757       0.0080         0.09       0.0588\n[14,]  0.4 -0.0416      -0.0931       0.0098         0.16       0.1046\n[15,]  0.5 -0.0507      -0.1132       0.0118         0.25       0.1634\n[16,]  0.6 -0.0617      -0.1378       0.0144         0.36       0.2353\n[17,]  0.7 -0.0764      -0.1706       0.0177         0.49       0.3202\n[18,]  0.8 -0.0990      -0.2209       0.0229         0.64       0.4182\n[19,]  0.9 -0.1458      -0.3252       0.0337         0.81       0.5293\n\nRho at which ACME = 0: -0.2\nR^2_M*R^2_Y* at which ACME = 0: 0.04\nR^2_M~R^2_Y~ at which ACME = 0: 0.0261 \n\nplot(sens.out)\n\n\n\n\n\n\n\n\nρ (rho) represents the correlation between residual confounders that affect both the mediator (job_seek) and the outcome (depress2). ρ = -0.2 means that for the mediation effect (ACME) to completely disappear, an unmeasured confounder would need to create a correlation of -0.2 between the errors in M and Y. Since ρ = -0.2 is relatively small, the mediation effect is somewhat sensitive to hidden confounders.\nThe graph shows how fast ACME approaches 0 as ρ increases. If the ACME estimate does not change much across different rho values, it means that the mediation effect is not highly sensitive to hidden confounding. In contrast, if ACME drops to zero (or changes drastically) with a small shift in rho, it indicates that even a small amount of unmeasured confounding could invalidate the mediation effect."
  },
  {
    "objectID": "Tutorial4.html#mediator-is-also-moderator",
    "href": "Tutorial4.html#mediator-is-also-moderator",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "Mediator is also moderator",
    "text": "Mediator is also moderator\nWe can also allow the causal mediation effect to vary with treatment status. Here, the model for the outcome must be altered by including an interaction term between the treatment indicator (treat) and the mediator variable (job_seek)\n\nmodel.y.inter &lt;- lm(depress2 ~ treat + job_seek + treat:job_seek + depress1 + econ_hard + sex + age + occp + marital + nonwhite + educ + income, data = jobs)\n\nout.2 &lt;- mediate(model.m, model.y.inter, sims = 1000, boot = TRUE, treat = \"treat\", mediator = \"job_seek\")\n\nRunning nonparametric bootstrap\n\nsummary(out.2)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n                         Estimate 95% CI Lower 95% CI Upper p-value\nACME (control)            -0.0185      -0.0451         0.00    0.10\nACME (treated)            -0.0117      -0.0298         0.00    0.10\nADE (control)             -0.0356      -0.1304         0.04    0.34\nADE (treated)             -0.0288      -0.1235         0.05    0.42\nTotal Effect              -0.0473      -0.1424         0.03    0.21\nProp. Mediated (control)   0.3920      -1.7387         3.50    0.26\nProp. Mediated (treated)   0.2482      -1.1572         2.35    0.26\nACME (average)            -0.0151      -0.0352         0.00    0.10\nADE (average)             -0.0322      -0.1251         0.04    0.38\nProp. Mediated (average)   0.3201      -1.3863         2.97    0.26\n\nSample Size Used: 899 \n\n\nSimulations: 1000 \n\n\nNow estimates for the mediation effects, direct effects and proportion of total effect mediated correspond to the levels of the treatment. In this case, the mediation effect under the treatment condition, listed as ACME (treated) is estimated to be −.012, while the mediation effect under the control condition, ACME (control), is −.019.\nBoth ACME values are negative, indicating that job-seeking behavior reduces depressive symptoms, regardless of whether individuals received treatment. However, the absolute value of ACME is larger for the control group (-0.0185) than for the treated group (-0.0117). This suggests that the indirect effect of job-seeking on depression is stronger when individuals did NOT receive treatment.\nWhen having a mediate object with interaction, we can select which treatment condition to plot the estimated effects for by selecting the treatment argument.\n\nplot(out.2, treatment = \"both\")\n\n\n\n\n\n\n\n#plot(out.2, treatment = \"treated\")\n#plot(out.2, treatment = \"control\")\n\nSolid lines represent treated group, and dotted lines represent control group. We can also make sensitivity plots for different treatment conditions.\n\nsens.out.2 &lt;- medsens(out.2, sims = 1000)\nsummary(sens.out.2)\n\n\nMediation Sensitivity Analysis: Average Mediation Effect\n\nSensitivity Region: ACME for Control Group\n\n       Rho ACME(control) 95% CI Lower 95% CI Upper R^2_M*R^2_Y* R^2_M~R^2_Y~\n [1,] -0.9        0.1133      -0.0264       0.2530         0.81       0.5279\n [2,] -0.8        0.0666      -0.0157       0.1489         0.64       0.4171\n [3,] -0.7        0.0441      -0.0107       0.0988         0.49       0.3194\n [4,] -0.6        0.0294      -0.0075       0.0662         0.36       0.2346\n [5,] -0.5        0.0183      -0.0054       0.0421         0.25       0.1629\n [6,] -0.4        0.0093      -0.0043       0.0230         0.16       0.1043\n [7,] -0.3        0.0015      -0.0061       0.0092         0.09       0.0587\n [8,] -0.2       -0.0055      -0.0155       0.0045         0.04       0.0261\n [9,] -0.1       -0.0121      -0.0288       0.0045         0.01       0.0065\n[10,]  0.0       -0.0185      -0.0425       0.0055         0.00       0.0000\n[11,]  0.1       -0.0250      -0.0566       0.0066         0.01       0.0065\n[12,]  0.2       -0.0316      -0.0712       0.0080         0.04       0.0261\n[13,]  0.3       -0.0386      -0.0868       0.0095         0.09       0.0587\n[14,]  0.4       -0.0464      -0.1040       0.0112         0.16       0.1043\n[15,]  0.5       -0.0554      -0.1240       0.0132         0.25       0.1629\n[16,]  0.6       -0.0664      -0.1486       0.0157         0.36       0.2346\n[17,]  0.7       -0.0811      -0.1813       0.0190         0.49       0.3194\n[18,]  0.8       -0.1037      -0.2316       0.0242         0.64       0.4171\n[19,]  0.9       -0.1504      -0.3357       0.0349         0.81       0.5279\n\nRho at which ACME for Control Group = 0: -0.3\nR^2_M*R^2_Y* at which ACME for Control Group = 0: 0.09\nR^2_M~R^2_Y~ at which ACME for Control Group = 0: 0.0587 \n\n\nSensitivity Region: ACME for Treatment Group\n\n       Rho ACME(treated) 95% CI Lower 95% CI Upper R^2_M*R^2_Y* R^2_M~R^2_Y~\n [1,] -0.9        0.1201      -0.0278       0.2681         0.81       0.5279\n [2,] -0.8        0.0734      -0.0171       0.1639         0.64       0.4171\n [3,] -0.7        0.0509      -0.0119       0.1137         0.49       0.3194\n [4,] -0.6        0.0362      -0.0086       0.0809         0.36       0.2346\n [5,] -0.5        0.0251      -0.0062       0.0564         0.25       0.1629\n [6,] -0.4        0.0161      -0.0043       0.0366         0.16       0.1043\n [7,] -0.3        0.0083      -0.0030       0.0197         0.09       0.0587\n [8,] -0.2        0.0013      -0.0038       0.0064         0.04       0.0261\n [9,] -0.1       -0.0053      -0.0135       0.0029         0.01       0.0065\n[10,]  0.0       -0.0117      -0.0270       0.0035         0.00       0.0000\n[11,]  0.1       -0.0182      -0.0410       0.0047         0.01       0.0065\n[12,]  0.2       -0.0248      -0.0557       0.0061         0.04       0.0261\n[13,]  0.3       -0.0318      -0.0713       0.0077         0.09       0.0587\n[14,]  0.4       -0.0396      -0.0886       0.0094         0.16       0.1043\n[15,]  0.5       -0.0486      -0.1087       0.0114         0.25       0.1629\n[16,]  0.6       -0.0596      -0.1332       0.0139         0.36       0.2346\n[17,]  0.7       -0.0743      -0.1660       0.0173         0.49       0.3194\n[18,]  0.8       -0.0969      -0.2163       0.0225         0.64       0.4171\n[19,]  0.9       -0.1436      -0.3204       0.0332         0.81       0.5279\n\nRho at which ACME for Treatment Group = 0: -0.2\nR^2_M*R^2_Y* at which ACME for Treatment Group = 0: 0.04\nR^2_M~R^2_Y~ at which ACME for Treatment Group = 0: 0.0261 \n\nplot(sens.out.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe mediation package is not limited to OLS models; it also supports mediation analysis for binary, ordinal, and other types of dependent variables, making it highly flexible for different study designs. For more details and documentation, visit the mediation package website."
  },
  {
    "objectID": "Tutorial4.html#parallel-mediation",
    "href": "Tutorial4.html#parallel-mediation",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "Parallel mediation",
    "text": "Parallel mediation\nIn parallel mediation, multiple mediators operate independently to explain the effect of an independent variable (X) on an outcome (Y). This means that each mediator contributes separately to the total mediation effect, without influencing each other.\nWe first write down the model specifying all relationships. The indirect effects are defined to capture the mediation pathways: one through interest (mstr_int_achv = a × b) and another through anxiety (mstr_anxt_achv = c × d). The total effect combines all direct and indirect effects, allowing us to assess the full impact of mastery on achievement.\n\nmodel &lt;- \"achieve ~ b*interest + d*anxiety + e*mastery\n          interest ~ a*mastery\n          anxiety ~ c*mastery\n          mstr_int_achv := a*b\n          mstr_anxt_achv := c*d\n          Total := a*b + c*d + e\n\"\n\nIn lavaan, the := operator is used to define custom parameters based on existing model estimates. This is particularly useful in mediation analysis, where indirect effects need to be explicitly computed from path coefficients.\n\nfit &lt;- sem(model, data = SEMdata, se=\"bootstrap\", bootstrap = 1000)\n\nWarning: lavaan-&gt;lav_model_nvcov_bootstrap():  \n   1 bootstrap runs failed or did not converge.\n\nsummary(fit, fit.measures = T, standardized = T, rsquare = T)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         8\n\n  Number of observations                           140\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.010\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.920\n\nModel Test Baseline Model:\n\n  Test statistic                               149.860\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.041\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -704.422\n  Loglikelihood unrestricted model (H1)       -704.417\n                                                      \n  Akaike (AIC)                                1424.844\n  Bayesian (BIC)                              1448.377\n  Sample-size adjusted Bayesian (SABIC)       1423.066\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.082\n  P-value H_0: RMSEA &lt;= 0.050                    0.933\n  P-value H_0: RMSEA &gt;= 0.080                    0.051\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.002\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws             999\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  achieve ~                                                             \n    interest   (b)    0.211    0.072    2.935    0.003    0.211    0.294\n    anxiety    (d)   -0.040    0.056   -0.722    0.470   -0.040   -0.053\n    mastery    (e)    0.345    0.096    3.591    0.000    0.345    0.379\n  interest ~                                                            \n    mastery    (a)    0.770    0.083    9.319    0.000    0.770    0.607\n  anxiety ~                                                             \n    mastery    (c)   -0.399    0.090   -4.436    0.000   -0.399   -0.337\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .achieve           0.988    0.102    9.737    0.000    0.988    0.613\n   .interest          1.973    0.229    8.609    0.000    1.973    0.631\n   .anxiety           2.415    0.211   11.439    0.000    2.415    0.886\n\nR-Square:\n                   Estimate\n    achieve           0.387\n    interest          0.369\n    anxiety           0.114\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    mstr_int_achv     0.162    0.057    2.856    0.004    0.162    0.178\n    mstr_anxt_achv    0.016    0.023    0.692    0.489    0.016    0.018\n    Total             0.524    0.067    7.776    0.000    0.524    0.575\n\n\nResults indicate that mastery goal has indirect effect of 0.162 on achievement through interest. But mastery goal doesn’t have indirect effect on achievement through anxiety. Mastery goal has total effect of 0.524 on achievement."
  },
  {
    "objectID": "Tutorial4.html#sequential-mediation",
    "href": "Tutorial4.html#sequential-mediation",
    "title": "Tutorial 4 Mediation Analysis",
    "section": "Sequential mediation",
    "text": "Sequential mediation\nIn sequential mediation, the mediators are causally dependent on each other, forming a chain-like process where the effect of the independent variable (X) is transmitted through multiple steps before reaching the outcome (Y). Unlike parallel mediation, where mediators operate independently, sequential mediation assumes that one mediator influences another before affecting Y. This allows researchers to explore how intermediate mechanisms unfold over time. For example, in an educational setting, mastery might first enhance interest, which then reduces anxiety, ultimately leading to higher achievement.\n\nmodel2 &lt;- \"achieve ~ c*anxiety + e*interest + f*mastery\n           interest ~ a*mastery\n           anxiety ~ b*interest + d*mastery\n           mstr_int_anxt_achv := a*b*c\n           mstr_int_achv := a*e\n           mstr_anxt_achv := d*c\n           int_anxt_achv := b*c\n           total_mstr := a*b*c + a*e + d*c + f\n           total_int := b*c + e\n\"\n\nNote that in sequential mediation, it is not enough to only compute the total and indirect effects of the initial treatment variable (mastery). Since mediators influence one another in a chain, we must also consider the total and indirect effects of the first mediator (interest) to fully capture the mediation process.\n\nfit2 &lt;- sem(model2, data = SEMdata, se=\"bootstrap\", bootstrap = 1000)\nsummary(fit2, fit.measures = T, standardized = T, rsquare = T)\n\nlavaan 0.6-19 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         9\n\n  Number of observations                           140\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               149.860\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -704.417\n  Loglikelihood unrestricted model (H1)       -704.417\n                                                      \n  Akaike (AIC)                                1426.834\n  Bayesian (BIC)                              1453.309\n  Sample-size adjusted Bayesian (SABIC)       1424.834\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  achieve ~                                                             \n    anxiety    (c)   -0.040    0.056   -0.723    0.470   -0.040   -0.053\n    interest   (e)    0.211    0.072    2.933    0.003    0.211    0.294\n    mastery    (f)    0.345    0.096    3.592    0.000    0.345    0.379\n  interest ~                                                            \n    mastery    (a)    0.770    0.083    9.310    0.000    0.770    0.607\n  anxiety ~                                                             \n    interest   (b)    0.009    0.099    0.095    0.924    0.009    0.010\n    mastery    (d)   -0.406    0.116   -3.508    0.000   -0.406   -0.343\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .achieve           0.988    0.101    9.741    0.000    0.988    0.613\n   .interest          1.973    0.229    8.606    0.000    1.973    0.631\n   .anxiety           2.415    0.212   11.382    0.000    2.415    0.886\n\nR-Square:\n                   Estimate\n    achieve           0.387\n    interest          0.369\n    anxiety           0.114\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    mstr_nt_nxt_ch   -0.000    0.006   -0.052    0.958   -0.000   -0.000\n    mstr_int_achv     0.162    0.057    2.857    0.004    0.162    0.178\n    mstr_anxt_achv    0.016    0.023    0.701    0.484    0.016    0.018\n    int_anxt_achv    -0.000    0.007   -0.053    0.958   -0.000   -0.001\n    total_mstr        0.524    0.067    7.778    0.000    0.524    0.575\n    total_int         0.211    0.071    2.952    0.003    0.211    0.293\n\n\nResults indicate that mastery goal has indirect effect of 0.162 on achievement through interest. But this indirect effect does not happen through anxiety. Mastery goal also show a total effect of 0.524 on achievement."
  },
  {
    "objectID": "Tutorial5.html",
    "href": "Tutorial5.html",
    "title": "Tutorial 5 Instrumental Variables",
    "section": "",
    "text": "Instrumental variable estimation is a crucial tool in causal inference, allowing researchers to address endogeneity and obtain unbiased estimates when treatment assignment is not purely random. This tutorial will guide you through implementing instrumental variable estimation in R using Two-Stage Least Squares (2SLS), as well as testing for endogeneity, weak instruments, and overidentification.\nBy the end of this tutorial, you will be familiar with:\n1. 2SLS in R\n2. Assessing instrument validity"
  },
  {
    "objectID": "Tutorial5.html#simple-regression-model",
    "href": "Tutorial5.html#simple-regression-model",
    "title": "Tutorial 5 Instrumental Variables",
    "section": "Simple regression model",
    "text": "Simple regression model\nWe first need to check if the independent variable (price) and the instrumental variable (sale tax) is correlated.\n\ncor(CigarettesSW$salestax, CigarettesSW$rprice)\n\n[1] 0.7035012\n\n\nSince x and z are highly correlated, we can move on to the 2SLS estimation.\nStep 1, \\[log(Price)=\\delta_0+\\delta_1Tax+v\\]\n\ncig_s1 &lt;- lm(log(rprice) ~ salestax, data = c1995)\nsummary(cig_s1)\n\n\nCall:\nlm(formula = log(rprice) ~ salestax, data = c1995)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.221027 -0.044324  0.000111  0.063730  0.210717 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.616546   0.029108   158.6  &lt; 2e-16 ***\nsalestax    0.030729   0.004802     6.4 7.27e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09394 on 46 degrees of freedom\nMultiple R-squared:  0.471, Adjusted R-squared:  0.4595 \nF-statistic: 40.96 on 1 and 46 DF,  p-value: 7.271e-08\n\n\nStep 2, we estimate the fitted values obtained by the first stage regression\nStep 2 predict endogenous variable price\n\nlcigp_pred &lt;- cig_s1$fitted.values\n\nStep 3, we run the second stage regression \\[log(packs)=\\beta_0+\\beta_1\\hat{log_price}+\\mu\\]\n\ncig_s2 &lt;- lm(log(c1995$packs) ~ lcigp_pred)\nsummary(cig_s2)\n\n\nCall:\nlm(formula = log(c1995$packs) ~ lcigp_pred)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.63180 -0.15802  0.00524  0.13574  0.61434 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.7199     1.8012   5.396  2.3e-06 ***\nlcigp_pred   -1.0836     0.3766  -2.877  0.00607 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2264 on 46 degrees of freedom\nMultiple R-squared:  0.1525,    Adjusted R-squared:  0.1341 \nF-statistic: 8.277 on 1 and 46 DF,  p-value: 0.006069\n\n\nNow we have the model \\[log(pack)=9.72-1.08log(price)\\]\nComparing the results of OLS regression, first, and second stage.\n\ncig_ols &lt;- lm(log(packs) ~ log(rprice),data=c1995)\n\nstargazer(cig_ols,cig_s1,cig_s2,type = \"text\")\n\n\n==============================================================\n                                    Dependent variable:       \n                              --------------------------------\n                              log(packs) log(rprice)  packs)  \n                                 (1)         (2)        (3)   \n--------------------------------------------------------------\nlog(rprice)                   -1.213***                       \n                               (0.216)                        \n                                                              \nsalestax                                  0.031***            \n                                           (0.005)            \n                                                              \nlcigp_pred                                           -1.084***\n                                                      (0.377) \n                                                              \nConstant                      10.339***   4.617***   9.720*** \n                               (1.035)     (0.029)    (1.801) \n                                                              \n--------------------------------------------------------------\nObservations                      48         48         48    \nR2                              0.406       0.471      0.152  \nAdjusted R2                     0.393       0.459      0.134  \nResidual Std. Error (df = 46)   0.190       0.094      0.226  \nF Statistic (df = 1; 46)      31.409***   40.956***  8.277*** \n==============================================================\nNote:                              *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nUsing OLS regression, a 1% increase in log(price) is associated with 1.21% decrease in log(pack). Using the 2SLS estimation, 1% increase in log(price) is associated with 1.08% decrease in log(pack), which is lower effect.\nHowever, although 2SLS correctly estimates the coefficient, the standard error needs to be corrected. The function ivreg() from the package AER carries out 2SLS procedure automatically and generates the same coefficient and corrected standard error. Now we see the standard error of log(rprice) in 2SLS model (0.317) is higher than the standard error from the OLS regression (0.216). The 2SLS model also reports a lower level of significance.\n\ncig_ivreg &lt;- ivreg(log(packs) ~ log(rprice) | salestax, data = c1995)\nsummary(cig_ivreg)\n\n\nCall:\nivreg(formula = log(packs) ~ log(rprice) | salestax, data = c1995)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.64619 -0.07732  0.02981  0.11283  0.41904 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.7199     1.5141   6.420 6.79e-08 ***\nlog(rprice)  -1.0836     0.3166  -3.422  0.00131 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1904 on 46 degrees of freedom\nMultiple R-Squared: 0.4011, Adjusted R-squared: 0.3881 \nWald test: 11.71 on 1 and 46 DF,  p-value: 0.001313"
  },
  {
    "objectID": "Tutorial5.html#multiple-regression-model",
    "href": "Tutorial5.html#multiple-regression-model",
    "title": "Tutorial 5 Instrumental Variables",
    "section": "Multiple regression model",
    "text": "Multiple regression model\nAfter learning the simple regression, let’s add income as a control variable.\n\n# add rincome to the dataset\nCigarettesSW$rincome &lt;- with(CigarettesSW, income / population / cpi)\nCigarettesSW$cigtax &lt;- with(CigarettesSW, tax/cpi)\n\nc1995 &lt;- subset(CigarettesSW, year == \"1995\")\n\nWe first estimate the model with one instrument (sales tax) and one control (income). In the function below, left of | shows the dependent variable log(packs), the endogenous variable log(rprice), and the exogenous variable, or control variable, log(rincome). Right of the | shows the exogenous variable log(rincome) and instrumental variable salestax.\n\ncig_ivreg2 &lt;- ivreg(log(packs) ~ log(rprice) + log(rincome) | log(rincome) + \n                    salestax, data = c1995)\nsummary(cig_ivreg2)\n\n\nCall:\nivreg(formula = log(packs) ~ log(rprice) + log(rincome) | log(rincome) + \n    salestax, data = c1995)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.611000 -0.086072  0.009423  0.106912  0.393159 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    9.4307     1.3584   6.943 1.24e-08 ***\nlog(rprice)   -1.1434     0.3595  -3.181  0.00266 ** \nlog(rincome)   0.2145     0.2686   0.799  0.42867    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1896 on 45 degrees of freedom\nMultiple R-Squared: 0.4189, Adjusted R-squared: 0.3931 \nWald test: 6.534 on 2 and 45 DF,  p-value: 0.003227 \n\n\nThe estimated regression equation is \\[log(packs)=9.4307−1.1434log(rprice)+0.2145log(rincome)\\] A 1% increase in cigarette price is associated with a 1.14% decrease in cigarette sales. The impact is statistically significant at 1% level.\nNow explore a model with one control (income) and two instruments (sales tax and cigtax). When the number of instruments exceeds the number of endogenous variables, the model is overidentified. This allows us to test the validity of the instruments using an overidentification test. More instruments can also help reduce standard errors in 2SLS, improving the statistical power of estimates.\nSame as the previous model, left of the | shows the dependent variable, endogenous variable, and the control variable. Right of the | shows the control variable, and two instrumental variables.\n\ncig_ivreg3 &lt;- ivreg(log(packs) ~ log(rprice) + log(rincome) | \n                    log(rincome) + salestax + cigtax, data = c1995)\nsummary(cig_ivreg3)\n\n\nCall:\nivreg(formula = log(packs) ~ log(rprice) + log(rincome) | log(rincome) + \n    salestax + cigtax, data = c1995)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.6006931 -0.0862222 -0.0009999  0.1164699  0.3734227 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    9.8950     1.0586   9.348 4.12e-12 ***\nlog(rprice)   -1.2774     0.2632  -4.853 1.50e-05 ***\nlog(rincome)   0.2804     0.2386   1.175    0.246    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1879 on 45 degrees of freedom\nMultiple R-Squared: 0.4294, Adjusted R-squared: 0.4041 \nWald test: 13.28 on 2 and 45 DF,  p-value: 2.931e-05 \n\n\nThe estimated regression equation is \\[log(packs)=9.8950−1.2774log(rprice)+0.2804log(rincome)\\] A 1% increase in cigarette price is associated with a 1.28% decrease in cigarette sales. The effect is highly significant."
  },
  {
    "objectID": "Tutorial5.html#weak-instrument-test",
    "href": "Tutorial5.html#weak-instrument-test",
    "title": "Tutorial 5 Instrumental Variables",
    "section": "Weak instrument test",
    "text": "Weak instrument test\nTo ensure the instruments (sales tax and cigarette tax) are strong predictors of the endogenous variable (log(rprice)), we perform a weak instrument test using the first-stage F-statistic.\nRule of thumb: If F &gt; 10, the instruments are strong; if F &lt; 10, they are weak, leading to biased IV estimates."
  },
  {
    "objectID": "Tutorial5.html#overidentification-test-sargan-hansen",
    "href": "Tutorial5.html#overidentification-test-sargan-hansen",
    "title": "Tutorial 5 Instrumental Variables",
    "section": "Overidentification test (Sargan-Hansen)",
    "text": "Overidentification test (Sargan-Hansen)\nWhen there are more instruments than endogenous variables, the model is overidentified, allowing us to test whether the instruments are truly exogenous. The Sargan-Hansen J-test checks if the instruments are uncorrelated with the error term. A high p-value (&gt;0.05) suggests that the instruments are valid, while a low p-value indicates that at least one instrument may be invalid. This test helps ensure that our IV estimates are not biased due to instrument endogeneity."
  },
  {
    "objectID": "Tutorial5.html#endogeneity-test-wu-hausman",
    "href": "Tutorial5.html#endogeneity-test-wu-hausman",
    "title": "Tutorial 5 Instrumental Variables",
    "section": "Endogeneity test (Wu-Hausman)",
    "text": "Endogeneity test (Wu-Hausman)\nThe Wu-Hausman test checks whether an explanatory variable is endogenous, meaning it is correlated with the error term. If endogeneity is present, OLS estimates are biased and inconsistent, making IV estimation necessary. The test compares the results of OLS and IV regressions – if the two estimates significantly differ, it suggests that the endogenous variable should be instrumented. A low p-value (p &lt; 0.05) indicates that OLS is biased, confirming the need for IV, while a high p-value suggests that OLS may be sufficient.\nWe can use one function to conduct all three tests:\n\nsummary(cig_ivreg3,diagnostics = T)\n\n\nCall:\nivreg(formula = log(packs) ~ log(rprice) + log(rincome) | log(rincome) + \n    salestax + cigtax, data = c1995)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-0.6006931 -0.0862222 -0.0009999  0.1164699  0.3734227 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    9.8950     1.0586   9.348 4.12e-12 ***\nlog(rprice)   -1.2774     0.2632  -4.853 1.50e-05 ***\nlog(rincome)   0.2804     0.2386   1.175    0.246    \n\nDiagnostic tests:\n                 df1 df2 statistic p-value    \nWeak instruments   2  44   244.734  &lt;2e-16 ***\nWu-Hausman         1  44     3.068  0.0868 .  \nSargan             1  NA     0.333  0.5641    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1879 on 45 degrees of freedom\nMultiple R-Squared: 0.4294, Adjusted R-squared: 0.4041 \nWald test: 13.28 on 2 and 45 DF,  p-value: 2.931e-05 \n\n\nResults show that:\nFirst, for weak instrument test, F&gt;10, confirming that sales tax and cigarette tax are strongly correelated with price. Weak instrument bias is not a concern.\nSecond, for endogeneity test, a low p-value (p &lt; 0.05) indicates that OLS is biased, and we should use instrumental variable. Since p&gt;0.05, we do not have strong evidence that log(rprice) is endogenous. So OLS may be sufficient, but IV can still be used if we suspect unobserved confounders.\nFinally, for overidentification test, the null hypothesis is the instruments are valid (uncorrelated with the error term). Since p&gt;0.05, we fail to reject the null hypothesis, meaning both sales tax and cigarette tax are likely valid instruments."
  },
  {
    "objectID": "Tutorial6.html",
    "href": "Tutorial6.html",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "",
    "text": "Panel data analysis is a powerful tool in causal inference, enabling researchers to control for unobserved, time-invariant confounding and analyze changes within units over time. This tutorial will guide you through key panel data methods in R, from data preparation to advanced causal modeling. We will use tidyverse tools to reshape and explore panel data, and estimate fixed effects, random effects, and nonlinear models. We’ll also explore how to extend these models to include mediation analysis and instrumental variables within a panel framework.\nBy the end of this tutorial, you will be familiar with:\n1 . The structure of panel data\n2 . Estimating fixed and random effects models\n3 . Models with nonlinear outcomes\n4 . Incorporating mediation and instrumental variable approaches in panel data"
  },
  {
    "objectID": "Tutorial6.html#textbook-example-data",
    "href": "Tutorial6.html#textbook-example-data",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Textbook Example data",
    "text": "Textbook Example data\nThis example dataset simulates a scenario where we observe multiple individuals over time and want to study the relationship between Intensity of Reminders (e.g., how often someone is nudged to eat healthy) and their Healthy Eating Score. The data includes four individuals, each observed eight times, with individual differences in both baseline behavior and response to reminders. This structure mimics panel data, where repeated observations are collected for the same units.\nThe code below generates this data, ensuring some variation in reminder intensity and healthy eating behavior across individuals and time. We’ll use this dataset to illustrate how different modeling strategies — including OLS, fixed effects, and demeaning — handle within- and between-individual variation.\n\nset.seed(2000)\nDemo &lt;- tibble(Individual = factor(c(rep('You',8),rep('Me',8),\n                                   rep('Shamma',8),rep('Liqing',8)),levels = c('Me','You','Liqing','Shamma')),\n             IndNo = sort(rep(1:4,8))) %&gt;%\n  mutate(IntensityOfReminders = runif(32)*5 + IndNo) %&gt;%\n  mutate(HealthyEatingScore = runif(32)*10 + IntensityOfReminders - 2*IndNo) %&gt;%\n  mutate(HealthyEatingScore = case_when(\n    HealthyEatingScore &lt; 0 ~ 0,\n    TRUE ~ HealthyEatingScore))\n\nhead(Demo)\n\n# A tibble: 6 × 4\n  Individual IndNo IntensityOfReminders HealthyEatingScore\n  &lt;fct&gt;      &lt;int&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n1 You            1                 1.98               1.20\n2 You            1                 4.58              11.7 \n3 You            1                 2.81               6.57\n4 You            1                 2.96               7.26\n5 You            1                 5.07               4.28\n6 You            1                 3.14              10.9 \n\n\nVisualization:\n\nggplot(Demo, aes(x = IntensityOfReminders,\n               y = HealthyEatingScore, \n               color = Individual)) + \n  geom_point() + \n  theme_pubr() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\")+\n  labs(x = \"Intensity of Reminders\",\n       y = \"Healthy Eating Score\")+\n  theme(text         = element_text(size = 13, family=\"Garamond\"),\n        axis.title.x = element_text(size = 13, family=\"Garamond\"),\n        axis.title.y = element_text(size = 13, family= \"Garamond\"))\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Tutorial6.html#ols-model",
    "href": "Tutorial6.html#ols-model",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "OLS model",
    "text": "OLS model\nWe begin with a simple Ordinary Least Squares (OLS) regression, where we estimate the relationship between Intensity of Reminders and Healthy Eating Score, ignoring individual differences. This model assumes that all individuals share the same intercept and slope — that is, it pools all observations together without accounting for the fact that each individual may have a different baseline level of healthy eating. While easy to estimate and interpret, this approach risks omitted variable bias if there are time-invariant individual characteristics (like personal motivation or lifestyle) that influence both the reminders and the outcome.\n\nmodel1 &lt;- lm(HealthyEatingScore~IntensityOfReminders, data=Demo)\nsummary(model1)\n\n\nCall:\nlm(formula = HealthyEatingScore ~ IntensityOfReminders, data = Demo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.7976 -2.8402  0.0088  2.0486  7.0025 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)            3.8820     1.6860   2.303   0.0284 *\nIntensityOfReminders   0.1850     0.3004   0.616   0.5427  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.311 on 30 degrees of freedom\nMultiple R-squared:  0.01248,   Adjusted R-squared:  -0.02044 \nF-statistic: 0.3791 on 1 and 30 DF,  p-value: 0.5427\n\n\n\\(y = 0.185X+3.882\\). This indicates that for each one-unit increase in reminder intensity, the Healthy Eating Score increases by 0.19 points. However, the p-value for this effect is 0.543, which indicates that the relationship is not statistically significant at conventional levels."
  },
  {
    "objectID": "Tutorial6.html#ols-model-with-individual-as-control",
    "href": "Tutorial6.html#ols-model-with-individual-as-control",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "OLS model with ‘individual’ as control",
    "text": "OLS model with ‘individual’ as control\n\nmodel2 &lt;- lm(HealthyEatingScore ~ IntensityOfReminders + Individual, data = Demo)\nsummary(model2)\n\n\nCall:\nlm(formula = HealthyEatingScore ~ IntensityOfReminders + Individual, \n    data = Demo)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3688 -2.2382 -0.0088  1.6162  4.6900 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)            0.7580     1.8078   0.419   0.6783  \nIntensityOfReminders   0.7448     0.3676   2.026   0.0527 .\nIndividualYou          3.3317     1.4802   2.251   0.0327 *\nIndividualLiqing      -2.2873     1.7970  -1.273   0.2139  \nIndividualShamma      -0.3349     1.7174  -0.195   0.8469  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.959 on 27 degrees of freedom\nMultiple R-squared:  0.2902,    Adjusted R-squared:  0.1851 \nF-statistic:  2.76 on 4 and 27 DF,  p-value: 0.04808\n\n\nIn the output, there’s a coefficient for each group, and ‘Me’ is treated as the baseline. The slope for Intensity of Reminders is now estimated at 0.74, meaning that for a one-unit increase in reminder intensity, the Healthy Eating Score increases by 0.74 points on average. The p-value is now 0.052. The intercept (0.76) represents the expected Healthy Eating Score for the reference individual (‘Me’) when Intensity of Reminders is 0. ‘You’ tends to score 3.33 points higher than Me (significant). ‘Liqing’ scores 2.29 points lower, but this is not statistically significant.\nWe can also visualize the results of this model to reinforce the logic. The plot below shows that each individual has their own intercept, while sharing the same slope for ‘Intensity of Reminders’. This aligns with the fixed effects idea: we allow each person to start from a different baseline, but we assume the effect of reminders is consistent across individuals.\n\n# Add predicted values for each observation\nDemo &lt;- Demo %&gt;%\n  mutate(Fitted = predict(model2))\n\n# Plot: Individual lines with shared slope, different intercepts\nggplot(Demo, aes(x = IntensityOfReminders, y = HealthyEatingScore, color = Individual)) +\n  geom_point(size = 2) +\n  geom_line(aes(y = Fitted), size = 1) +\n  labs(title = \"Fixed Effects Logic: Common Slope, Varying Intercepts\",\n       x = \"Intensity of Reminders\",\n       y = \"Healthy Eating Score\") +\n  theme_minimal(base_family = \"Garamond\") +\n  theme(text = element_text(size = 13))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Tutorial6.html#de-meaned-model",
    "href": "Tutorial6.html#de-meaned-model",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "De-meaned model",
    "text": "De-meaned model\nAnother way to estimate a fixed effects model is by manually demeaning the data — that is, subtracting each individual’s mean from their own observations. This removes all between-individual variation, leaving only the within-individual variation over time. When we run a regression on the demeaned variables, we get the same slope as a fixed effects model, since we’ve effectively controlled for all time-invariant individual characteristics.\nThis approach is useful for illustrating the logic of fixed effects and helps students see exactly what is being removed from the data.\n\nDemo_demeaned &lt;- Demo %&gt;%\n  group_by(Individual) %&gt;%\n  mutate(\n    Y_demeaned = HealthyEatingScore - mean(HealthyEatingScore),\n    X_demeaned = IntensityOfReminders - mean(IntensityOfReminders)\n  ) %&gt;%\n  ungroup()\n\n# Run the model\nmodel3 &lt;- lm(Y_demeaned ~ X_demeaned, data = Demo_demeaned)\nsummary(model3)\n\n\nCall:\nlm(formula = Y_demeaned ~ X_demeaned, data = Demo_demeaned)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3688 -2.2382 -0.0088  1.6162  4.6900 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 2.739e-16  4.962e-01   0.000    1.000  \nX_demeaned  7.448e-01  3.487e-01   2.136    0.041 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.807 on 30 degrees of freedom\nMultiple R-squared:  0.132, Adjusted R-squared:  0.103 \nF-statistic: 4.561 on 1 and 30 DF,  p-value: 0.04098\n\n\nSame as model2, the slope for Intensity of Reminders is still 0.74, meaning that for a one-unit increase in reminder intensity, the Healthy Eating Score increases by 0.74 points on average. This confirms that demeaning preserves the within-unit effect. The p-value is now 0.041, indicating a statistically significant positive relationship at the 5% level.\nThe intercept is essentially zero and not significant — this is expected. Since we’ve demeaned both the outcome and the predictor, the mean of each is zero by construction. That’s why the intercept is near zero and meaningless in this context."
  },
  {
    "objectID": "Tutorial6.html#fixed-effects",
    "href": "Tutorial6.html#fixed-effects",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Fixed effects",
    "text": "Fixed effects\nThe most efficient and flexible way to estimate a fixed effects model in R is by using the fixest package. This package allows us to easily specify fixed effects using the | operator, without manually creating dummy variables or demeaning the data. Here, we include Individual as a fixed effect to account for time-invariant differences across individuals, while estimating a common slope for ‘IntensityOfReminders’.\nThis approach is mathematically equivalent to both the OLS with individual dummies and the demeaned model. However, fixest handles fixed effects more efficiently and also supports clustered standard errors, multi-way fixed effects, and IV estimation — making it a preferred choice for applied panel data analysis.\n\nmodel4 &lt;- feols(HealthyEatingScore ~ IntensityOfReminders | Individual, data = Demo)\nsummary(model4)\n\nOLS estimation, Dep. Var.: HealthyEatingScore\nObservations: 32\nFixed-effects: Individual: 4\nStandard-errors: Clustered (Individual) \n                     Estimate Std. Error t value Pr(&gt;|t|) \nIntensityOfReminders 0.744796    0.47583 1.56526  0.21549 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.71763     Adj. R2: 0.185071\n                Within R2: 0.131979\n\n\nThe output indicates that we have 32 observations within 4 groups. The standard error is clustered, which is the default of feols function."
  },
  {
    "objectID": "Tutorial6.html#comparing-four-models",
    "href": "Tutorial6.html#comparing-four-models",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Comparing four models",
    "text": "Comparing four models\n\nstargazer(model1, model2, model3, \n          type = \"text\",\n          title = \"Comparison of OLS, Individual Controls, Demeaned, and Fixed Effects Models\",\n          column.labels = c(\"OLS\", \"OLS + Individual\", \"Demeaned\", \"Fixed Effects\"),\n          dep.var.labels = \"Healthy Eating Score\")\n\n\nComparison of OLS, Individual Controls, Demeaned, and Fixed Effects Models\n=================================================================================\n                                         Dependent variable:                     \n                     ------------------------------------------------------------\n                              Healthy Eating Score                Y_demeaned     \n                            OLS           OLS + Individual         Demeaned      \n                            (1)                 (2)                  (3)         \n---------------------------------------------------------------------------------\nIntensityOfReminders       0.185               0.745*                            \n                          (0.300)             (0.368)                            \n                                                                                 \nIndividualYou                                 3.332**                            \n                                              (1.480)                            \n                                                                                 \nIndividualLiqing                               -2.287                            \n                                              (1.797)                            \n                                                                                 \nIndividualShamma                               -0.335                            \n                                              (1.717)                            \n                                                                                 \nX_demeaned                                                         0.745**       \n                                                                   (0.349)       \n                                                                                 \nConstant                  3.882**              0.758                0.000        \n                          (1.686)             (1.808)              (0.496)       \n                                                                                 \n---------------------------------------------------------------------------------\nObservations                 32                  32                   32         \nR2                         0.012               0.290                0.132        \nAdjusted R2                -0.020              0.185                0.103        \nResidual Std. Error   3.311 (df = 30)     2.959 (df = 27)      2.807 (df = 30)   \nF Statistic          0.379 (df = 1; 30) 2.760** (df = 4; 27) 4.561** (df = 1; 30)\n=================================================================================\nNote:                                                 *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nThe logic is the same across model2, model3 and model4, and they all give you the same slope — but small differences in how the model handles variation and estimates standard errors can lead to slightly different p-values. In practice, we usually rely on packages like fixest for efficiency and robust SEs."
  },
  {
    "objectID": "Tutorial6.html#clustered-standard-errors",
    "href": "Tutorial6.html#clustered-standard-errors",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Clustered standard errors",
    "text": "Clustered standard errors\nClustered standard errors adjust for the fact that observations within the same group (or “cluster”) — such as individuals in panel data — may not be independent of one another. In panel data, for example, repeated measurements from the same person are likely correlated. If we ignore this and treat all observations as independent, our standard errors may be too small, leading to overstated statistical significance. Clustered standard errors correct for this by allowing for arbitrary correlation of errors within each cluster, making our inference (like p-values and confidence intervals) more reliable.\nWe can get heteroskedasticity-robust standard errors using this function:\n\nsummary(model4, vcov = \"hetero\")  \n\nOLS estimation, Dep. Var.: HealthyEatingScore\nObservations: 32\nFixed-effects: Individual: 4\nStandard-errors: Heteroskedasticity-robust \n                     Estimate Std. Error t value Pr(&gt;|t|)    \nIntensityOfReminders 0.744796   0.392933 1.89548 0.068782 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.71763     Adj. R2: 0.185071\n                Within R2: 0.131979\n\n\nWe see that for the model with clustered standard error, the p-value is 0.22, meaning that the effect is not statistically significant at conventional levels in this specification. But for the model with heteroskedasticity-robust standard errors, the p-value is 0.07, which supports what we said earlier: If we ignore this and treat all observations as independent, our standard errors may be too small, leading to overstated statistical significance.\nYou may also notice there is no ‘intercept’ in the model output of the fixed effects model. This is because fixed effects absorb the intercepts by estimating a separate intercept for each individual. Instead of reporting a single overall intercept, the model includes individual-specific fixed effects that capture each person’s baseline level of the outcome.\nYou can view these estimated individual intercepts using the fixef() function:\n\nfixef(model4)\n\n$Individual\n    Liqing         Me     Shamma        You \n-1.5292183  0.7580456  0.4231911  4.0897559 \n\nattr(,\"class\")\n[1] \"fixest.fixef\" \"list\"        \nattr(,\"exponential\")\n[1] FALSE"
  },
  {
    "objectID": "Tutorial6.html#practice-twfe",
    "href": "Tutorial6.html#practice-twfe",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Practice TWFE",
    "text": "Practice TWFE\nNow, let’s have a practice using real cross-country time series data: the gapminder dataset. This dataset includes information on life expectancy, GDP per capita, and population size for countries around the world from 1952 to 2007, in five-year increments. It provides a simple but effective example of panel data where each country is observed repeatedly over time. We’ll use this dataset to estimate a two-way fixed effects model, controlling for both country-specific characteristics (like geography, health infrastructure, or culture) and time-specific shocks (like global medical advances or economic downturns).\n\nlibrary(gapminder)\n\n# Rename for consistency\ndf &lt;- gapminder %&gt;%\n  rename(country = country, year = year,\n         life_exp = lifeExp,\n         gdp_pc = gdpPercap) %&gt;%\n  mutate(log_pop = log(pop))\n\nhead(df)\n\n# A tibble: 6 × 7\n  country     continent  year life_exp      pop gdp_pc log_pop\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Afghanistan Asia       1952     28.8  8425333   779.    15.9\n2 Afghanistan Asia       1957     30.3  9240934   821.    16.0\n3 Afghanistan Asia       1962     32.0 10267083   853.    16.1\n4 Afghanistan Asia       1967     34.0 11537966   836.    16.3\n5 Afghanistan Asia       1972     36.1 13079460   740.    16.4\n6 Afghanistan Asia       1977     38.4 14880372   786.    16.5\n\n\nOur outcome of interest will be life expectancy, and we’ll examine how it is associated with GDP per capita, while controlling for population size.\n\nmodel_gap_FE &lt;- feols(life_exp ~ log(gdp_pc) + log_pop | country, data = df)\nmodel_gap_TWFE &lt;- feols(life_exp ~ log(gdp_pc) + log_pop | country + year, data = df)\n\n\nsummary(model_gap_FE)\n\nOLS estimation, Dep. Var.: life_exp\nObservations: 1,704\nFixed-effects: country: 142\nStandard-errors: Clustered (country) \n            Estimate Std. Error  t value   Pr(&gt;|t|)    \nlog(gdp_pc)  4.47740   0.555508  8.06001 2.9408e-13 ***\nlog_pop     11.95839   0.664803 17.98789  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 3.09349     Adj. R2: 0.937351\n                Within R2: 0.779557\n\nsummary(model_gap_TWFE)\n\nOLS estimation, Dep. Var.: life_exp\nObservations: 1,704\nFixed-effects: country: 142,  year: 12\nStandard-errors: Clustered (country) \n            Estimate Std. Error t value   Pr(&gt;|t|)    \nlog(gdp_pc)  2.98160   0.765053 3.89725 1.4984e-04 ***\nlog_pop      8.32135   1.050069 7.92458 6.2636e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.96801     Adj. R2: 0.941921\n                Within R2: 0.189886\n\n\nLet’s compare the results from the one-way fixed effects model (country only) and the two-way fixed effects model (country and year).\nIn the one-way fixed effects model, the estimated effect of log(gdp_pc) on life expectancy is 4.48, while in the two-way fixed effects model, the estimate drops to 2.98. Similarly, the effect of log_pop decreases from 11.96 to 8.32. These differences suggest that once we control for year-specific shocks – such as global medical advances, international development programs, or major world events – the explanatory power of GDP and population size becomes more conservative. That is, GDP still has a positive association with life expectancy, but the effect is smaller once we account for trends that influence all countries in a given year.\nWe also see changes in model fit statistics. The RMSE (Root Mean Squared Error), which tells us the average prediction error in the units of life expectancy, drops slightly from 3.09 to 2.97, indicating that the two-way fixed effects model makes slightly more accurate predictions overall. However, the within R² decreases dramatically from 0.78 to 0.19. This may seem surprising, but it’s expected. When we include year fixed effects, we absorb more variation from the outcome variable (life expectancy), leaving less variation for GDP and population to explain. That doesn’t mean the model is worse – it just means that more confounding variation has been removed."
  },
  {
    "objectID": "Tutorial6.html#clustered-standard-error",
    "href": "Tutorial6.html#clustered-standard-error",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Clustered standard error",
    "text": "Clustered standard error\nBy default, when we fit a fixed effects model using feols() with multiple fixed effects (e.g., country + year), the standard errors are clustered by the first fixed effect – in this case, country. This makes sense, as we usually want to account for serial correlation within each unit over time.\nIf you want to change the clustering variable, you can explicitly specify it using the cluster argument directly in the model:\n\nmodel_twfe_clustered &lt;- feols(life_exp ~ log(gdp_pc) + log_pop | country + year, \n                              cluster = ~year,\n                              data = df)\nsummary(model_twfe_clustered)\n\nOLS estimation, Dep. Var.: life_exp\nObservations: 1,704\nFixed-effects: country: 142,  year: 12\nStandard-errors: Clustered (year) \n            Estimate Std. Error t value   Pr(&gt;|t|)    \nlog(gdp_pc)  2.98160   0.117151 25.4509 3.9736e-11 ***\nlog_pop      8.32135   0.609468 13.6535 3.0544e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.96801     Adj. R2: 0.941921\n                Within R2: 0.189886\n\n\nIn the example above, we clustered standard errors by year, which allows for arbitrary correlation of errors across countries within the same year. This is useful for demonstration purposes to show how clustering affects inference. However, in practice, especially when working with panel data, it is more common to cluster by the unit of observation – in this case, country – because observations within the same country over time are likely to be correlated. Clustering by country accounts for serial correlation in the residuals and typically produces more conservative standard errors, which helps ensure valid statistical inference."
  },
  {
    "objectID": "Tutorial6.html#hausman-test-should-we-trust-random-effects",
    "href": "Tutorial6.html#hausman-test-should-we-trust-random-effects",
    "title": "Tutorial 6 Panel Data Analysis",
    "section": "Hausman Test: Should We Trust Random Effects?",
    "text": "Hausman Test: Should We Trust Random Effects?\nThe Hausman test allows us to formally test whether the random effects model is appropriate. The null hypothesis is that the random effects model is consistent – in other words, that there is no correlation between the unit effects and the regressors. If the test rejects the null, we should use fixed effects.\n\n# Hausman test\nhausman_result &lt;- phtest(fe_model, re_model)\nhausman_result\n\n\n    Hausman Test\n\ndata:  lifeExp ~ log(gdpPercap) + log(pop)\nchisq = 7075.6, df = 2, p-value &lt; 2.2e-16\nalternative hypothesis: one model is inconsistent\n\n\np-value is smaller than 0.05, so we reject the null , and should use fixed effects (random effects are likely biased). This test helps you decide between fixed and random effects not based on fit alone, but based on the core assumption about unobserved heterogeneity in your panel data."
  },
  {
    "objectID": "Tutorial7.html",
    "href": "Tutorial7.html",
    "title": "Tutorial 7 Difference in Differences",
    "section": "",
    "text": "Difference-in-Differences (DID) is a foundational method in causal inference, used to estimate treatment effects in observational settings by comparing treated and untreated units over time. This tutorial walks you through the key steps in implementing DID in R. You’ll learn how to prepare data for DID analysis, visualize group trends, and estimate treatment effects using interaction models. We’ll also explore techniques to assess the credibility of your assumptions and extend the basic DID framework to handle more complex research designs.\nBy the end of this tutorial, you will be familiar with:\n1 . Basic Difference-in-Differences (DID) model\n2 . Evaluating the parallel trends assumption\n3 . Exploring the long-term effects of treatment\n4 . Modeling rollout designs"
  },
  {
    "objectID": "Tutorial7.html#test-of-prior-trends",
    "href": "Tutorial7.html#test-of-prior-trends",
    "title": "Tutorial 7 Difference in Differences",
    "section": "Test of prior trends",
    "text": "Test of prior trends\nBefore we can trust a Difference-in-Differences (DID) estimate, we need to evaluate whether the treated and control groups were following similar trends before the treatment — this is known as the parallel trends assumption. One way to assess this is by running a prior trend test, which looks only at pre-treatment data. In this test, we regress the outcome on time (as a numeric variable), a treatment group indicator, and an interaction between the two. The key idea is that if the two groups had similar trends before treatment, the interaction term — which captures whether the slope differs by group — should be statistically indistinguishable from zero.\n\n# Only use pre-treatmeent data\nod_pre &lt;- causaldata::organ_donations %&gt;%\n  filter(Quarter_Num &lt;= 3) %&gt;%\n  mutate(\n    Time = Quarter_Num,                      # numeric time\n    Group = if_else(State == \"California\", 1, 0)\n  )\n\n# Estimate linear trend test\npriortrend &lt;-feols(Rate ~ Time + Time:Group | State, data = od_pre)\nsummary(priortrend)\n\nOLS estimation, Dep. Var.: Rate\nObservations: 81\nFixed-effects: State: 27\nStandard-errors: Clustered (State) \n           Estimate Std. Error  t value Pr(&gt;|t|) \nTime       0.002379   0.002493 0.954120  0.34881 \nTime:Group 0.001471   0.002493 0.590058  0.56025 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.01259     Adj. R2: 0.990071\n                Within R2: 0.024607\n\n\nThe output from our prior trend test shows that the coefficient on the interaction term (Time × Group) is approximately 0.0015, with a p-value of 0.56. This suggests that there is no statistically significant difference in the linear trend of donor registration rates between California and the control states during the pre-treatment period. In other words, California and the control states were on parallel paths before the policy was implemented, supporting the validity of the DID design."
  },
  {
    "objectID": "Tutorial7.html#placebo-test",
    "href": "Tutorial7.html#placebo-test",
    "title": "Tutorial 7 Difference in Differences",
    "section": "Placebo Test",
    "text": "Placebo Test\nTo test the plausibility of the parallel trends assumption, we can also conduct a placebo test using only pre-treatment data. We create two fake treatment indicators: one pretending California was treated in both Q1 and Q2 of 2011, and another pretending the treatment occurred only in Q2 2011. We then re-estimate the same DID model as before, but using these fake treatment periods. If the estimated effects are close to zero and statistically insignificant, this supports the idea that California and the control states were following similar trends prior to the actual policy change.\n\n# Use only pre-treatment data\nod &lt;- causaldata::organ_donations %&gt;%\n    filter(Quarter_Num &lt;= 3)\n\n# Create our fake treatment variables\nod &lt;- od %&gt;%\n    mutate(FakeTreat1 = State == 'California' & \n           Quarter %in% c('Q12011','Q22011'),\n           FakeTreat2 = State == 'California' &\n           Quarter == 'Q22011')\n\n# Run the same model we did before but with our fake treatment\nplacebo1 &lt;- feols(Rate ~ FakeTreat1 | State + Quarter,\n    data = od)\nplacebo2 &lt;- feols(Rate ~ FakeTreat2 | State + Quarter,\n  data = od)\n\nsummary(placebo1)\n\nOLS estimation, Dep. Var.: Rate\nObservations: 81\nFixed-effects: State: 27,  Quarter: 3\nStandard-errors: Clustered (State) \n               Estimate Std. Error t value Pr(&gt;|t|) \nFakeTreat1TRUE  0.00609   0.005088 1.19698  0.24211 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.012373     Adj. R2: 0.990222\n                 Within R2: 0.001917\n\nsummary(placebo2)\n\nOLS estimation, Dep. Var.: Rate\nObservations: 81\nFixed-effects: State: 27,  Quarter: 3\nStandard-errors: Clustered (State) \n                Estimate Std. Error  t value Pr(&gt;|t|) \nFakeTreat2TRUE -0.001677   0.002797 -0.59958  0.55398 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.012384     Adj. R2: 0.990205\n                 Within R2: 1.453e-4\n\n\nThe results from the placebo test show that neither fake treatment variable produces a statistically significant effect. For FakeTreat1, the estimated effect is 0.0061 with a p-value of 0.24. For FakeTreat2, the estimate is –0.0017 with a p-value of 0.55. Both coefficients are small in magnitude and far from statistical significance. This suggests that California and the control states did not exhibit differential trends during the pre-treatment period, which supports the parallel trends assumption underlying the Difference-in-Differences design."
  },
  {
    "objectID": "Tutorial7.html#setting-treatment-group-variable",
    "href": "Tutorial7.html#setting-treatment-group-variable",
    "title": "Tutorial 7 Difference in Differences",
    "section": "Setting Treatment Group Variable",
    "text": "Setting Treatment Group Variable\nTo set up the Difference-in-Differences design, we first define the treatment group and the treatment period. In this example, countries labeled E, F, and G are considered the treated group — meaning they received the hypothetical policy intervention. All other countries form the control group. The treatment is assumed to begin in 1994, so we create a binary post variable that equals 1 for all years 1994 and later, and 0 for years prior to 1994. These two variables — treated and post — allow us to construct the did interaction term, which identifies observations that belong to the treated group after the policy went into effect.\n\n# Identifying post and prior treatment\nPracData$post = ifelse(PracData$year &gt;= 1994, 1, 0)\n\n# Idntifying treated group\nPracData$treated = ifelse(PracData$country == \"E\" |\n                          PracData$country == \"F\" |\n                          PracData$country == \"G\", 1, 0)"
  },
  {
    "objectID": "Tutorial7.html#placebo-test-1",
    "href": "Tutorial7.html#placebo-test-1",
    "title": "Tutorial 7 Difference in Differences",
    "section": "Placebo test",
    "text": "Placebo test\nTo conduct a placebo test, we use only the pre-treatment period (before 1994) and create a fake treatment variable. This variable pretends that the treatment (policy change) occurred in 1992 and 1993. By running our DID model on this restricted dataset, we check whether a treatment effect appears when there should be none. If we observe a significant effect, that may indicate differences in pre-treatment trends — which would violate the parallel trends assumption.\n\n# Use only pre-treatment data\ndata_pre &lt;- PracData %&gt;%\n  filter(year &lt; 1994) %&gt;%\n  mutate(\n    FakeTreat1 = treated == 1 & year %in% c(1992, 1993),\n    FakeTreat2 = treated == 1 & year == 1993\n  )\n\n# Run placebo DID models\nplacebo1 &lt;- feols(y ~ FakeTreat1 | country + year, data = data_pre)\nplacebo2 &lt;- feols(y ~ FakeTreat2 | country + year, data = data_pre)\n\n# View model results\nsummary(placebo1)\n\nOLS estimation, Dep. Var.: y\nObservations: 28\nFixed-effects: country: 7,  year: 4\nStandard-errors: Clustered (country) \n                 Estimate Std. Error   t value Pr(&gt;|t|) \nFakeTreat1TRUE -234344010 1705222917 -0.137427  0.89519 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.76e+9     Adj. R2: 0.403872\n                Within R2: 0.001084\n\nsummary(placebo2)\n\nOLS estimation, Dep. Var.: y\nObservations: 28\nFixed-effects: country: 7,  year: 4\nStandard-errors: Clustered (country) \n                  Estimate Std. Error   t value Pr(&gt;|t|) \nFakeTreat2TRUE -1748993355 2383172366 -0.733893  0.49069 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1.721e+9     Adj. R2: 0.430244\n                 Within R2: 0.045275\n\n\nThe fact that neither FakeTreat1 nor FakeTreat2 is statistically significant supports the parallel trends assumption."
  },
  {
    "objectID": "Tutorial7.html#did",
    "href": "Tutorial7.html#did",
    "title": "Tutorial 7 Difference in Differences",
    "section": "DID",
    "text": "DID\n\nPracData &lt;- PracData %&gt;%\n  mutate(did = treated * post)\n\ndid_model &lt;- feols(y ~ did | country + year, data = PracData)\nsummary(did_model)\n\nOLS estimation, Dep. Var.: y\nObservations: 70\nFixed-effects: country: 7,  year: 10\nStandard-errors: Clustered (country) \n       Estimate Std. Error  t value Pr(&gt;|t|)    \ndid -2519511630 1086212146 -2.31954 0.059486 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.343e+9     Adj. R2: 0.202443\n                 Within R2: 0.063637\n\n\nThe DID estimate suggests that the treatment led to a reduction of approximately 2.52 billion units in the outcome for the treated countries, relative to the change observed in the control group. The result is marginally significant at the 10% level"
  },
  {
    "objectID": "Tutorial7.html#did-with-control",
    "href": "Tutorial7.html#did-with-control",
    "title": "Tutorial 7 Difference in Differences",
    "section": "DID with control",
    "text": "DID with control\nIn addition to accounting for treatment status and timing, we can improve our DID model by including additional covariates that may influence the outcome. In this dataset, variables such as X1, X2, X3, and opinion can be added to control for country-level characteristics that vary over time and might confound the estimated treatment effect. This approach reflects more realistic applications of DID in observational data settings.\n\ndid_controls &lt;- feols(y ~ did + x1 + x2+ x3+ opinion | country + year, data = PracData)\n\nsummary(did_controls)\n\nOLS estimation, Dep. Var.: y\nObservations: 70\nFixed-effects: country: 7,  year: 10\nStandard-errors: Clustered (country) \n                    Estimate Std. Error   t value  Pr(&gt;|t|)    \ndid              -3730844599  784865728 -4.753481 0.0031474 ** \nx1                2438456300  904991473  2.694452 0.0358396 *  \nx2                -170490301 1408750858 -0.121022 0.9076245    \nx3                 703676005  327708965  2.147259 0.0753910 .  \nopinionAgree      -439601291 1236224249 -0.355600 0.7343080    \nopinionDisag      1299662757  871649340  1.491039 0.1865439    \nopinionStr disag   894696656  895667398  0.998916 0.3564016    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.129e+9     Adj. R2: 0.257532\n                 Within R2: 0.226996\n\n\nThe DID estimate suggests that the treatment led to a reduction of approximately 3.73.52 billion units in the outcome for the treated countries, relative to the change observed in the control group, after controling the effects of x1, x2, x3, and opinion. The result is marginally significant at the 5% level"
  },
  {
    "objectID": "Tutorial7.html#long-term-effect-1",
    "href": "Tutorial7.html#long-term-effect-1",
    "title": "Tutorial 7 Difference in Differences",
    "section": "Long term effect",
    "text": "Long term effect\n\n# Estimate dynamic treatment effects by interacting year with treated group\nlongterm &lt;- feols(y ~ i(year, treated, ref = 1993) | country + year, data = PracData)\n\n# Summary of estimates\nsummary(longterm)\n\nOLS estimation, Dep. Var.: y\nObservations: 70\nFixed-effects: country: 7,  year: 10\nStandard-errors: Clustered (country) \n                      Estimate Std. Error   t value Pr(&gt;|t|)    \nyear::1990:treated  1878879632 3389741077  0.554284 0.599419    \nyear::1991:treated   978954411 2705563477  0.361830 0.729880    \nyear::1992:treated  2389146024 2543433095  0.939339 0.383815    \nyear::1994:treated  -353480357 1076719789 -0.328294 0.753844    \nyear::1995:treated -6693704891 2961983098 -2.259873 0.064559 .  \nyear::1996:treated  -451797160 2728622050 -0.165577 0.873928    \nyear::1997:treated   773399515 2888441628  0.267757 0.797853    \nyear::1998:treated -2977579631 5207486242 -0.571788 0.588230    \nyear::1999:treated  2456562845 2772778388  0.885957 0.409741    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 2.034e+9     Adj. R2: 0.291941\n                 Within R2: 0.294189\n\n# Visualize effects over time\ncoefplot(longterm)\n\n\n\n\n\n\n\n\nInterestingly, while the Average Treatment Effect on the Treated (ATT) from the standard DID model is statistically significant, none of the individual post-treatment coefficients in the long-term effects model are significant (Well, the effect in 1995 is marginally significant). This can happen when the average effect is consistent but small across periods, or when individual year estimates have more noise and wider confidence intervals, reducing statistical power. It’s also possible that the effect is spread out or varies slightly across time, making no single year stand out on its own. This highlights the importance of looking at both the overall effect and the dynamics of treatment — even when individual time-point effects are not significant, the overall DID estimate can still capture a real, average shift attributable to the treatment."
  },
  {
    "objectID": "Tutorial8.html",
    "href": "Tutorial8.html",
    "title": "Tutorial 8 Matching",
    "section": "",
    "text": "Matching is a powerful tool for causal inference in observational studies. It helps reduce selection bias by constructing a comparison group that closely resembles the treatment group on observed covariates. This tutorial walks you through key types of matching methods and strategies, from simple exact matching to more flexible or model-based approaches. You’ll learn how to implement matching in R, interpret matched results, and decide when to combine matching with regression.\nBy the end of this tutorial, you will be familiar with:\n1. Exact Matching\n2. Distance Matching (e.g., Mahalanobis distance)\n3. Propensity Score Matching (PSM)\n4. Coarsened Exact Matching (CEM)\n5.Matching and Regression Adjustment\n\nFront-end Matters\nIn this tutorial, we will primarily use the MatchIt package in R, which provides a unified and user-friendly interface for implementing a wide range of matching methods, including exact matching, Mahalanobis distance matching, and propensity score matching. MatchIt is widely used in applied causal inference and integrates smoothly with tools for assessing balance and post-matching analysis. For methods not currently supported by MatchIt – such as Coarsened Exact Matching (CEM) – we will use dedicated package cem. These tools allow us to explore the strengths and limitations of different approaches and understand how implementation choices can affect our causal estimates.\n\n#install.packages(\"MatchIt\")\n#install.packages(\"cem\")\n\nlibrary(MatchIt)\nlibrary(cem)\n\nLoading required package: tcltk\n\n\nLoading required package: lattice\n\n\n\nHow to use CEM? Type vignette(\"cem\")\n\n\nThe dataset we’re using for this tutorial is the lalonde dataset from the MatchIt package. It comes from a well-known job training study and includes both treated and control groups, as well as covariates like age, education, race, and pre-treatment earnings. This dataset is widely used in causal inference because it’s simple, real, and flexible—it works well with all the matching methods we’re covering, including exact matching, distance matching, propensity score matching, coarsened exact matching, entropy balancing, and matching combined with regression.\n\ndata(\"lalonde\")\nhead(lalonde)\n\n     treat age educ   race married nodegree re74 re75       re78\nNSW1     1  37   11  black       1        1    0    0  9930.0460\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940\nNSW3     1  30   12  black       0        0    0    0 24909.4500\nNSW4     1  27   11  black       0        1    0    0  7506.1460\nNSW5     1  33    8  black       0        1    0    0   289.7899\nNSW6     1  22    9  black       0        1    0    0  4056.4940\n\n\n\n\nExact Matching\nExact matching is the most straightforward matching method, where treated and control units are matched only if they have identical values on all selected covariates. It guarantees perfect covariate balance within matched pairs or groups, making it conceptually clean and easy to interpret. However, it becomes difficult to implement when covariates are continuous or when there are many variables, as exact matches become increasingly rare. Despite this limitation, exact matching is a valuable foundation for understanding more flexible matching methods and is especially useful in clean, low-dimensional datasets.\n\nmatch_single &lt;- matchit(treat ~ race, data = lalonde, method = \"exact\")\nsummary(match_single)\n\n\nCall:\nmatchit(formula = treat ~ race, data = lalonde, method = \"exact\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\n           eCDF Max\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nraceblack         0.8432        0.8432               0          .         0\nracehispan        0.0595        0.0595               0          .         0\nracewhite         0.0973        0.0973               0          .         0\n           eCDF Max Std. Pair Dist.\nraceblack         0               0\nracehispan        0               0\nracewhite         0               0\n\nSample Sizes:\n              Control Treated\nAll               429     185\nMatched (ESS)     121     185\nMatched           429     185\nUnmatched           0       0\nDiscarded           0       0\n\n\nAfter performing exact matching on the race variable using the Lalonde dataset, we see that covariate balance improved substantially. Before matching, the distribution of race was highly imbalanced between treated and control groups—for example, 84% of treated units were Black, compared to only 20% of controls. After matching, the race proportions are perfectly aligned across groups, as expected from exact matching: every matched pair has the same race category.\nThe summary reports that all 185 treated units were matched to 429 control units, with an effective sample size (ESS) of 121 for the control group. ESS tells us how much unique, independent information those matched controls contribute—after accounting for weighting or reuse. In the output, the ESS for controls is 121, even though 429 were matched.This means many control units were reused, which is common when matching with replacement.\nThe key takeaway here is that while exact matching on one variable (race) ensures perfect balance on that variable, it does not address imbalance on other covariates like age or education. Also, although no units were discarded, the ESS reminds us that reuse of controls may reduce precision when estimating treatment effects.\n\n# Get matched data\nmatched_data &lt;- match.data(match_single)\n\n# Estimate ATT as difference in means\nmean(matched_data$re78[matched_data$treat == 1]) -\nmean(matched_data$re78[matched_data$treat == 0])\n\n[1] -635.0262\n\n\nAfter performing exact matching, we can estimate the treatment effect using the matched data. By taking the difference between the means of treated and control groups, we get the Average Treatment Effect on the Treated (ATT). In this case, the result is –635.03, which means that, on average, individuals who received the treatment earned $635 less than their matched counterparts who did not. While the matching step ensures that the two groups are balanced on the covariate used (race), this negative result suggests that race alone may not be sufficient to control for all confounding. Adding more covariates to the matching process may give a more accurate estimate. That’s why we are matching on multiple variables next.\n\n# Exact Matching on multiple variables (e.g., race, education, and age)\nmatch_multi &lt;- matchit(treat ~ race + educ + age, data = lalonde, method = \"exact\")\nsummary(match_multi)\n\n\nCall:\nmatchit(formula = treat ~ race + educ + age, data = lalonde, \n    method = \"exact\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\n           eCDF Max\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\neduc         0.1114\nage          0.1577\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nraceblack         0.7500        0.7500               0          .         0\nracehispan        0.0694        0.0694               0          .         0\nracewhite         0.1806        0.1806               0          .         0\neduc             10.5833       10.5833               0     0.9923         0\nage              21.6389       21.6389               0     0.9923         0\n           eCDF Max Std. Pair Dist.\nraceblack         0               0\nracehispan        0               0\nracewhite         0               0\neduc              0               0\nage               0               0\n\nSample Sizes:\n              Control Treated\nAll            429.       185\nMatched (ESS)   46.51      72\nMatched         85.        72\nUnmatched      344.       113\nDiscarded        0.         0\n\n\nAfter performing exact matching on multiple covariates (race, educ, and age), the means for all covariates were perfectly aligned between the treated and control groups. This is expected from exact matching, which only retains pairs that are exactly the same on the specified covariates.\nHowever, this improved balance comes at a cost: out of 185 treated units, only 72 could be matched; and from 429 controls, only 85 were used. The ESS for controls drops even further to around 46, reflecting the downweighting of reused or overlapping units. This is a common trade-off with exact matching—perfect balance, but reduced sample size and precision. Still, it serves as a strong baseline for comparing other, more flexible matching methods.\n\n# Get matched data\nmatched_data &lt;- match.data(match_multi)\n\n# Estimate ATT as difference in means\nmean(matched_data$re78[matched_data$treat == 1]) -\nmean(matched_data$re78[matched_data$treat == 0])\n\n[1] -381.3731\n\n\nThe ATT is –381, meaning treated individuals earned $381 less on average than their matched control counterparts. This is smaller (less negative) than our earlier estimate from matching only on race (–635), suggesting that adding more covariates has helped create a more comparable control group and reduced confounding. However, because exact matching on multiple variables is stricter, fewer treated units were matched, which may affect the precision of our estimate.\n\n\nDistance Matching (Mahalanobis Distance)\nDistance matching selects control units for each treated unit based on how similar they are across multiple covariates, using a distance metric like Mahalanobis distance. This approach works well with continuous variables and doesn’t require exact matches. It accounts for differences across all matching variables simultaneously and selects the best matches based on how “close” units are in multivariate space. Below, we use Mahalanobis distance matching to compare treated and control units in the Lalonde dataset based on age, education, and race.\n\nmatch_mahal &lt;- matchit(treat ~ age + educ + race,\n                       data = lalonde,\n                       method = \"nearest\",\n                       distance = \"mahalanobis\")\n#                      ratio=3\n# include this line for k-nearest-neighbor where k=3)\n\n# Summary of matching results\nsummary(match_mahal)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race, data = lalonde, \n    method = \"nearest\", distance = \"mahalanobis\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\n           eCDF Max\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.8162       26.0973         -0.0393     0.6929    0.0316\neduc             10.3459       10.5892         -0.1210     0.7775    0.0174\nraceblack         0.8432        0.4703          1.0259          .    0.3730\nracehispan        0.0595        0.0595          0.0000          .    0.0000\nracewhite         0.0973        0.4703         -1.2585          .    0.3730\n           eCDF Max Std. Pair Dist.\nage          0.0919          0.3460\neduc         0.1243          0.3092\nraceblack    0.3730          1.0259\nracehispan   0.0000          0.0000\nracewhite    0.3730          1.2585\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       185     185\nUnmatched     244       0\nDiscarded       0       0\n\n# Extract matched data\nmatched_mahal &lt;- match.data(match_mahal)\n\n# Estimate ATT\nmean(matched_mahal$re78[matched_mahal$treat == 1]) -\nmean(matched_mahal$re78[matched_mahal$treat == 0])\n\n[1] 76.39395\n\n\nAfter performing 1-to-1 Mahalanobis distance matching, we estimate the ATT using the matched sample. The result is 76.39, meaning that treated individuals earned $76 more on average than their matched control counterparts. This positive treatment effect contrasts with earlier estimates from exact matching, which were negative. Matching on multiple continuous covariates using Mahalanobis distance helps improve comparability and may lead to more accurate effect estimates—though we should still assess covariate balance and interpret results cautiously, especially with a modest effect size like this.\n\n\nPropensity Score Matching\nPropensity Score Matching (PSM) is a widely used method for reducing selection bias in observational studies. Instead of matching directly on all covariates, PSM first estimates the propensity score—the probability of receiving the treatment given observed covariates – typically using logistic regression. Treated and control units are then matched based on how close their propensity scores are. This simplifies the matching problem to a one-dimensional scale while attempting to balance the distribution of all covariates. Below, we estimate the propensity score and perform nearest-neighbor matching to evaluate the treatment effect.\n\n# Propensity score matching (1-to-1 nearest neighbor)\nmatch_psm &lt;- matchit(\n  treat ~ age + educ + race + nodegree + married + re74 + re75,\n  data = lalonde,\n  method = \"nearest\",           # matching approach\n  distance = \"logit\",           # propensity score model \n  caliper = 0.1,                # optional: only match a control unit if its propensity scoree is within 0.1 of the treated unit's score. Avoid bad matches. \n  replace = TRUE                # allow controls to be reused\n)\n\n# Summary of matching result\nsummary(match_psm)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + nodegree + married + \n    re74 + re75, data = lalonde, method = \"nearest\", distance = \"logit\", \n    replace = TRUE, caliper = 0.1)\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5774        0.1822          1.7941     0.9211    0.3774\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\ndistance     0.6444\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nnodegree     0.1114\nmarried      0.3236\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5746        0.5741          0.0021     0.9878    0.0029\nage              25.6776       24.1475          0.2138     0.5351    0.0770\neduc             10.3388       10.3716         -0.0163     0.5773    0.0219\nraceblack         0.8415        0.8361          0.0150          .    0.0055\nracehispan        0.0601        0.0656         -0.0231          .    0.0055\nracewhite         0.0984        0.0984          0.0000          .    0.0000\nnodegree          0.7049        0.6995          0.0120          .    0.0055\nmarried           0.1913        0.1311          0.1535          .    0.0601\nre74           2118.4761     2361.9980         -0.0498     1.0376    0.0410\nre75           1505.8050     1482.3283          0.0073     2.1018    0.0648\n           eCDF Max Std. Pair Dist.\ndistance     0.0492          0.0112\nage          0.3333          1.2479\neduc         0.0601          1.0980\nraceblack    0.0055          0.0451\nracehispan   0.0055          0.3004\nracewhite    0.0000          0.0546\nnodegree     0.0055          0.8774\nmarried      0.0601          0.5162\nre74         0.2186          0.6154\nre75         0.2350          0.6437\n\nSample Sizes:\n              Control Treated\nAll            429.       185\nMatched (ESS)   47.37     183\nMatched         82.       183\nUnmatched      347.         2\nDiscarded        0.         0\n\n# Extract matched dataset\nmatched_psm &lt;- match.data(match_psm)\n\n# Estimate ATT\nmean(matched_psm$re78[matched_psm$treat == 1]) -\nmean(matched_psm$re78[matched_psm$treat == 0])\n\n[1] 1645.175\n\n\nAfter performing Propensity Score Matching, we estimate the ATT using the matched dataset. The result is 1645.18, which means that treated individuals earned $1,645 more on average than their matched control counterparts in 1978. This positive effect is substantially larger than the results we observed with exact or Mahalanobis matching. By matching on the estimated probability of receiving treatment – rather than raw covariates – PSM attempts to balance all observed covariates simultaneously. However, this result should be interpreted with caution, as PSM is highly dependent on the correct specification of the propensity score model and may still be sensitive to imbalance or poor overlap.\nA Love plot is a simple and effective way to visualize covariate balance before and after matching. It displays the standardized mean differences (SMDs) for each covariate, allowing you to assess how well matching reduced imbalance between treated and control groups. In the plot, you typically want all post-matching dots to fall close to zero (e.g., within ±0.1), indicating good balance.\n\nlibrary(cobalt)\n\n cobalt (Version 4.5.5, Build Date: 2024-04-02)\n\n\n\nAttaching package: 'cobalt'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    lalonde\n\n\nThe following object is masked from 'package:MatchIt':\n\n    lalonde\n\nlove.plot(match_psm, threshold = 0.1)\n\nWarning: Standardized mean differences and raw mean differences are present in the same plot. \nUse the `stars` argument to distinguish between them and appropriately label the x-axis.\n\n\n\n\n\n\n\n\n\nWhile most covariates show improved balance after propensity score matching, age remains slightly imbalanced, with a standardized mean difference just beyond the ±0.1 threshold. This suggests the PSM model may need to be refined – perhaps by adding interactions, higher-order terms, or considering a caliper restriction to enforce closer matches.\n\n\nCoarsened Exact Matching\nCoarsened Exact Matching (CEM) is a flexible matching method that improves on traditional exact matching by binning continuous variables into broader categories, or “coarsened” groups. Instead of requiring exact matches on precise values (which can be too strict), CEM allows treated and control units to be matched exactly within coarsened bins, such as age ranges or income brackets. This method balances covariates by design, reduces model dependence, and retains interpretability. It is particularly useful when covariates are a mix of categorical and continuous variables.\n\n# function from cem package\ncem_out &lt;- cem(\n  treatment = \"treat\",\n  data = lalonde,\n  drop = \"re78\",  # don't match on outcome\n  cutpoints = list(\n    age = c(20, 25, 30, 35, 40, 45),    \n    re74 = c(0, 5000, 10000, 20000),\n    re75 = c(0, 5000, 10000, 20000)\n  )# coarsen continuous variables into bins\n)\n\n\nUsing 'treat'='1' as baseline group\n\nsummary(cem_out)\n\n               Length Class  Mode     \ncall             3    -none- call     \nstrata         614    -none- numeric  \nn.strata         1    -none- numeric  \nvars             7    -none- character\ndrop             2    -none- character\nbreaks           6    -none- list     \ntreatment        1    -none- character\nn                1    -none- numeric  \ngroups         614    factor numeric  \ng.names          2    -none- character\nn.groups         1    -none- numeric  \ngroup.idx        2    -none- list     \ngroup.len        2    -none- numeric  \nmstrata        614    -none- numeric  \nmstrataID       33    -none- numeric  \nmatched        614    -none- logical  \nbaseline.group   1    -none- character\ntab              6    -none- numeric  \nk2k              1    -none- logical  \nw              614    -none- numeric  \n\n\nThis summary gives you the internal structure of the cem object. While it’s not very reader-friendly on its own, here are the most important pieces:\n\nw: This is the vector of weights. Each observation in your dataset gets a weight—usually: 0 if the unit was unmatched; 1 (or higher) if it was matched and kept. These weights are used to estimate the weighted ATT\nmatched: A logical vector indicating which rows were matched (TRUE) and which were discarded (FALSE).\ncutpoints (in breaks): These show how continuous variables (like age, re74, re75) were binned into categories.\ntab: Gives counts of how many treated and control units were in each matched stratum.\n\n\n# Estimate ATT manually using matched weights\ncem_matched &lt;- lalonde\ncem_matched$weights &lt;- cem_out$w\nwith(cem_matched, weighted.mean(re78[treat == 1], weights[treat == 1]) -\n                   weighted.mean(re78[treat == 0], weights[treat == 0]))\n\n[1] 357.244\n\n\nThis code calculates the ATT after CEM. It uses the weights assigned by the matching procedure to compute the weighted mean outcome (re78) separately for treated and control units. Then it subtracts the two means to estimate the ATT. In this case, the result is 357.24, meaning that treated individuals earned $357 more on average than their matched control counterparts. This estimate reflects comparisons within well-balanced strata created by coarsening the covariates, making it more robust to model misspecification than some other methods like propensity score matching.\n\n\nMatching and Regression\nAfter matching, we can further refine our treatment effect estimates by running a regression model on the matched sample. This approach is useful because matching alone may not perfectly balance all covariates or remove all bias. Running a regression on matched data allows us to adjust for any remaining imbalance and can also improve statistical efficiency (e.g., by reducing variance). Importantly, regression after matching is more trustworthy because it is based on better covariate overlap and requires fewer functional form assumptions than regression on the full, unmatched sample.\n\n# We already have the matched data\nhead(cem_matched)\n\n     treat age educ   race married nodegree re74 re75       re78 weights\nNSW1     1  37   11  black       1        1    0    0  9930.0460       1\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940       1\nNSW3     1  30   12  black       0        0    0    0 24909.4500       1\nNSW4     1  27   11  black       0        1    0    0  7506.1460       0\nNSW5     1  33    8  black       0        1    0    0   289.7899       0\nNSW6     1  22    9  black       0        1    0    0  4056.4940       1\n\nreg_cem &lt;- lm(re78 ~ treat + age + educ + race + nodegree + married + re74 + re75,\n              data = cem_matched,\n              weights = weights)\n\nreg_original &lt;- lm(re78 ~ treat + age + educ + race + nodegree + married + re74 + re75,\n              data = lalonde)\n\nsummary(reg_cem)\n\n\nCall:\nlm(formula = re78 ~ treat + age + educ + race + nodegree + married + \n    re74 + re75, data = cem_matched, weights = weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n-13622      0      0      0  26971 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  2.873e+03  4.572e+03   0.628   0.5305  \ntreat        6.419e+02  7.871e+02   0.815   0.4158  \nage         -5.608e+01  6.373e+01  -0.880   0.3799  \neduc         3.945e+02  3.257e+02   1.211   0.2274  \nracehispan   4.176e+03  1.844e+03   2.264   0.0247 *\nracewhite    7.575e+02  1.406e+03   0.539   0.5907  \nnodegree    -1.726e+03  1.360e+03  -1.270   0.2057  \nmarried     -1.787e+03  1.861e+03  -0.960   0.3382  \nre74        -8.817e-02  2.308e-01  -0.382   0.7028  \nre75         5.126e-01  3.558e-01   1.441   0.1512  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5522 on 194 degrees of freedom\nMultiple R-squared:  0.08608,   Adjusted R-squared:  0.04368 \nF-statistic:  2.03 on 9 and 194 DF,  p-value: 0.03789\n\nsummary(reg_original)\n\n\nCall:\nlm(formula = re78 ~ treat + age + educ + race + nodegree + married + \n    re74 + re75, data = lalonde)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-13595  -4894  -1662   3929  54570 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.174e+03  2.456e+03  -0.478   0.6328    \ntreat        1.548e+03  7.813e+02   1.982   0.0480 *  \nage          1.298e+01  3.249e+01   0.399   0.6897    \neduc         4.039e+02  1.589e+02   2.542   0.0113 *  \nracehispan   1.740e+03  1.019e+03   1.708   0.0882 .  \nracewhite    1.241e+03  7.688e+02   1.614   0.1071    \nnodegree     2.598e+02  8.474e+02   0.307   0.7593    \nmarried      4.066e+02  6.955e+02   0.585   0.5590    \nre74         2.964e-01  5.827e-02   5.086 4.89e-07 ***\nre75         2.315e-01  1.046e-01   2.213   0.0273 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6948 on 604 degrees of freedom\nMultiple R-squared:  0.1478,    Adjusted R-squared:  0.1351 \nF-statistic: 11.64 on 9 and 604 DF,  p-value: &lt; 2.2e-16\n\n\nAfter estimating ATT with regression on both the original and the CEM-matched datasets, we observe the following:\n\nOriginal Data (no matching): The coefficient for treat is $1,548 and statistically significant (p = 0.048). But this model relies on stronger functional form assumptions and extrapolates across imbalanced groups.\nCEM-Matched Data + Weighted Regression: The coefficient for treat drops to $642 and is not statistically significant (p = 0.416). This model is estimated on a more balanced sample, thanks to coarsened exact matching, and is likely more reliable even if the effect is smaller and noisier."
  }
]