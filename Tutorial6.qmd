---
title: "Tutorial 6 Panel Data Analysis"
pagetitle: Tutorial_6
---

Panel data analysis is a powerful tool in causal inference, enabling researchers to control for unobserved, time-invariant confounding and analyze changes within units over time. This tutorial will guide you through key panel data methods in R, from data preparation to advanced causal modeling. We will use tidyverse tools to reshape and explore panel data, and estimate fixed effects, random effects, and nonlinear models. We'll also explore how to extend these models to include mediation analysis and instrumental variables within a panel framework.

By the end of this tutorial, you will be familiar with:

1 . The structure of panel data

2 . Estimating fixed and random effects models

3 . Models with nonlinear outcomes

4 . Incorporating mediation and instrumental variable approaches in panel data

# Front-end Matters

We use `fixest` package for fixed effect model. For random effect, we also use the `plm` package. For mediation analysis and instrumental variable in panel data, we'll use a combination of `fixest` and the packages we introduced earlier: `mediation` and `AER`.

The `fixest` package is a powerful and efficient tool for estimating fixed effects models in R. It supports multi-way fixed effects (e.g., individual and time), clustered standard errors, and instrumental variable estimation — all with a clean and flexible syntax. It’s well-suited for large datasets and is increasingly popular in applied causal inference research.

The `plm` package is a classic package for panel data analysis in R. It provides a consistent interface for estimating fixed effects, random effects, and other panel-specific models like first differences and between estimators. While it’s less flexible than `fixest`, it remains a useful tool for learning core panel data methods and comparing estimation strategies like fixed vs. random effects.

```{r}
library(tidyverse)
library(stargazer)
library(mediation)
library(AER)
library(ggpubr)


#install.packages("fixest")
#install.packages("plm")
library(fixest)
library(plm)
```

# The structure of panel data

Panel data consists of observations on multiple units (such as individuals, countries, or firms) tracked over multiple time periods. It involves observing the same units across time, although not every unit needs to appear in every time period — this is known as an unbalanced panel. Each row represents a unit at a specific time point, forming a long-format structure. This setup enables researchers to study within-unit change over time while controlling for time-invariant characteristics. By combining both cross-sectional and time-series dimensions, panel data offers powerful opportunities for causal inference.

This is an example of long-format panel data:

```{r}
tidydata <- table1
tidydata
```

But sometimes, when we receive data, it doesn’t come in the long format required for panel data analysis. Instead, it may be in a wide format, where repeated measurements for each unit (e.g., different years) appear as separate columns.

```{r}
untidydata <- table4a
untidydata
```

We’ll need to reshape this data into long format using `pivot_longer()` before we can analyze it as panel data.

```{r}
longer <- untidydata |>
  pivot_longer(c(`1999`, `2000`), names_to = "year", values_to = "cases")
#specifying the columns by column names

longer
```

# Fixed Effect

## Textbook Example data

This example dataset simulates a scenario where we observe multiple individuals over time and want to study the relationship between Intensity of Reminders (e.g., how often someone is nudged to eat healthy) and their Healthy Eating Score. The data includes four individuals, each observed eight times, with individual differences in both baseline behavior and response to reminders. This structure mimics panel data, where repeated observations are collected for the same units.

The code below generates this data, ensuring some variation in reminder intensity and healthy eating behavior across individuals and time. We'll use this dataset to illustrate how different modeling strategies — including OLS, fixed effects, and demeaning — handle within- and between-individual variation.

```{r}
set.seed(2000)
Demo <- tibble(Individual = factor(c(rep('You',8),rep('Me',8),
                                   rep('Shamma',8),rep('Liqing',8)),levels = c('Me','You','Liqing','Shamma')),
             IndNo = sort(rep(1:4,8))) %>%
  mutate(IntensityOfReminders = runif(32)*5 + IndNo) %>%
  mutate(HealthyEatingScore = runif(32)*10 + IntensityOfReminders - 2*IndNo) %>%
  mutate(HealthyEatingScore = case_when(
    HealthyEatingScore < 0 ~ 0,
    TRUE ~ HealthyEatingScore))

head(Demo)
```

Visualization:

```{r}
ggplot(Demo, aes(x = IntensityOfReminders,
               y = HealthyEatingScore, 
               color = Individual)) + 
  geom_point() + 
  theme_pubr() +
  geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed")+
  labs(x = "Intensity of Reminders",
       y = "Healthy Eating Score")+
  theme(text         = element_text(size = 13, family="Garamond"),
        axis.title.x = element_text(size = 13, family="Garamond"),
        axis.title.y = element_text(size = 13, family= "Garamond"))
```

## OLS model

We begin with a simple Ordinary Least Squares (OLS) regression, where we estimate the relationship between Intensity of Reminders and Healthy Eating Score, ignoring individual differences. This model assumes that all individuals share the same intercept and slope — that is, it pools all observations together without accounting for the fact that each individual may have a different baseline level of healthy eating. While easy to estimate and interpret, this approach risks omitted variable bias if there are time-invariant individual characteristics (like personal motivation or lifestyle) that influence both the reminders and the outcome.

```{r}
model1 <- lm(HealthyEatingScore~IntensityOfReminders, data=Demo)
summary(model1)
```

$y = 0.185X+3.882$. This indicates that for each one-unit increase in reminder intensity, the Healthy Eating Score increases by 0.19 points. However, the p-value for this effect is 0.543, which indicates that the relationship is not statistically significant at conventional levels.

## OLS model with 'individual' as control

```{r}
model2 <- lm(HealthyEatingScore ~ IntensityOfReminders + Individual, data = Demo)
summary(model2)
```

In the output, there's a coefficient for each group, and 'Me' is treated as the baseline. The slope for Intensity of Reminders is now estimated at 0.74, meaning that for a one-unit increase in reminder intensity, the Healthy Eating Score increases by 0.74 points on average. The p-value is now 0.052. The intercept (0.76) represents the expected Healthy Eating Score for the reference individual ('Me') when Intensity of Reminders is 0. 'You' tends to score 3.33 points higher than Me (significant). 'Liqing' scores 2.29 points lower, but this is not statistically significant.

We can also visualize the results of this model to reinforce the logic. The plot below shows that each individual has their own intercept, while sharing the same slope for 'Intensity of Reminders'. This aligns with the fixed effects idea: we allow each person to start from a different baseline, but we assume the effect of reminders is consistent across individuals.

```{r}
# Add predicted values for each observation
Demo <- Demo %>%
  mutate(Fitted = predict(model2))

# Plot: Individual lines with shared slope, different intercepts
ggplot(Demo, aes(x = IntensityOfReminders, y = HealthyEatingScore, color = Individual)) +
  geom_point(size = 2) +
  geom_line(aes(y = Fitted), size = 1) +
  labs(title = "Fixed Effects Logic: Common Slope, Varying Intercepts",
       x = "Intensity of Reminders",
       y = "Healthy Eating Score") +
  theme_minimal(base_family = "Garamond") +
  theme(text = element_text(size = 13))
```

## De-meaned model

Another way to estimate a fixed effects model is by manually demeaning the data — that is, subtracting each individual's mean from their own observations. This removes all between-individual variation, leaving only the within-individual variation over time. When we run a regression on the demeaned variables, we get the same slope as a fixed effects model, since we've effectively controlled for all time-invariant individual characteristics.

This approach is useful for illustrating the logic of fixed effects and helps students see exactly what is being removed from the data.

```{r}
Demo_demeaned <- Demo %>%
  group_by(Individual) %>%
  mutate(
    Y_demeaned = HealthyEatingScore - mean(HealthyEatingScore),
    X_demeaned = IntensityOfReminders - mean(IntensityOfReminders)
  ) %>%
  ungroup()

# Run the model
model3 <- lm(Y_demeaned ~ X_demeaned, data = Demo_demeaned)
summary(model3)
```

Same as model2, the slope for Intensity of Reminders is still 0.74, meaning that for a one-unit increase in reminder intensity, the Healthy Eating Score increases by 0.74 points on average. This confirms that demeaning preserves the within-unit effect. The p-value is now 0.041, indicating a statistically significant positive relationship at the 5% level.

The intercept is essentially zero and not significant — this is expected. Since we’ve demeaned both the outcome and the predictor, the mean of each is zero by construction. That’s why the intercept is near zero and meaningless in this context.

## Fixed effects

The most efficient and flexible way to estimate a fixed effects model in R is by using the `fixest` package. This package allows us to easily specify fixed effects using the `|` operator, without manually creating dummy variables or demeaning the data. Here, we include Individual as a fixed effect to account for time-invariant differences across individuals, while estimating a common slope for 'IntensityOfReminders'.

This approach is mathematically equivalent to both the OLS with individual dummies and the demeaned model. However, fixest handles fixed effects more efficiently and also supports clustered standard errors, multi-way fixed effects, and IV estimation — making it a preferred choice for applied panel data analysis.

```{r}
model4 <- feols(HealthyEatingScore ~ IntensityOfReminders | Individual, data = Demo)
summary(model4)
```

The output indicates that we have 32 observations within 4 groups. The standard error is clustered, which is the default of `feols` function.

## Clustered standard errors

**Clustered standard errors** adjust for the fact that observations within the same group (or "cluster") — such as individuals in panel data — may not be independent of one another. In panel data, for example, repeated measurements from the same person are likely correlated. If we ignore this and treat all observations as independent, our standard errors may be too small, leading to overstated statistical significance. Clustered standard errors correct for this by allowing for arbitrary correlation of errors within each cluster, making our inference (like p-values and confidence intervals) more reliable.

We can get heteroskedasticity-robust standard errors using this function:

```{r}
summary(model4, vcov = "hetero")  
```

We see that for the model with clustered standard error, the p-value is 0.22, meaning that the effect is not statistically significant at conventional levels in this specification. But for the model with heteroskedasticity-robust standard errors, the p-value is 0.07, which supports what we said earlier: If we ignore this and treat all observations as independent, our standard errors may be too small, leading to overstated statistical significance.

You may also notice there is no 'intercept' in the model output of the fixed effects model. This is because fixed effects absorb the intercepts by estimating a separate intercept for each individual. Instead of reporting a single overall intercept, the model includes individual-specific fixed effects that capture each person’s baseline level of the outcome.

You can view these estimated individual intercepts using the `fixef()` function:

```{r}
fixef(model4)
```

## Comparing four models

```{r}
stargazer(model1, model2, model3, 
          type = "text",
          title = "Comparison of OLS, Individual Controls, Demeaned, and Fixed Effects Models",
          column.labels = c("OLS", "OLS + Individual", "Demeaned", "Fixed Effects"),
          dep.var.labels = "Healthy Eating Score")
          
```

The logic is the same across model2, model3 and model4, and they all give you the same slope — but small differences in how the model handles variation and estimates standard errors can lead to slightly different p-values. In practice, we usually rely on packages like `fixest` for efficiency and robust SEs.

# Two-way Fixed Effect

In the previous sections, we used fixed effects to control for unobserved, time-invariant differences between individuals — such as personality, baseline health, or preferences. However, in many panel data settings, there may also be time-specific shocks that affect all individuals in the same period, such as policy changes, economic shifts, or public health campaigns. Two-way fixed effects (TWFE) models address this by adding both individual and time fixed effects, allowing us to control for who someone is and when the observation occurred. This helps isolate the effect of a treatment or variable of interest by removing bias from both stable individual characteristics and shared time shocks.

For demonstration purposes, we add a simple fake time variable to our dataset, assuming each individual is observed across eight time periods. This allows us to simulate a panel structure with both individual and time dimensions. We then estimate two models: a standard fixed effects model with only individual fixed effects (model_fe), and a two-way fixed effects model that includes both individual and time fixed effects (model_twfe). The two-way model controls not only for each person's baseline behavior but also for any year-specific effects that may influence the outcome. This is particularly useful when we suspect that external events — such as national trends or policy shifts — may impact all individuals during the same period.

```{r}
# Add fake time variable for demo
set.seed(2000)
Demo$Time <- rep(1:8, times = 4)  # assuming 8 time points

# Fit both models
model_fe   <- feols(HealthyEatingScore ~ IntensityOfReminders | Individual, data = Demo)
model_twfe <- feols(HealthyEatingScore ~ IntensityOfReminders | Individual + Time, data = Demo)

summary(model_fe)
summary(model_twfe)
```

In the two-way fixed effects (TWFE) model, the estimated effect of 'IntensityOfReminders' on 'HealthyEatingScore' is 0.91, compared to 0.74 in the standard fixed effects (FE) model. This suggests that, after controlling for both individual characteristics and common time effects, the effect of reminder intensity is stronger than what the one-way FE model estimated.

The p-value for the TWFE model is 0.096, indicating the effect is marginally significant at the 10% level, while the FE model’s p-value was higher (0.215), suggesting non-significance. This shift implies that time fixed effects may have reduced noise or bias in the original model — potentially caused by unobserved events affecting all individuals in a given time period.

Additionally, the RMSE (root mean squared error) decreased from 2.72 (FE) to 2.37 (TWFE), indicating a better model fit with the inclusion of time fixed effects.

## Practice TWFE

Now, let's have a practice using real cross-country time series data: the gapminder dataset. This dataset includes information on life expectancy, GDP per capita, and population size for countries around the world from 1952 to 2007, in five-year increments. It provides a simple but effective example of panel data where each country is observed repeatedly over time. We’ll use this dataset to estimate a two-way fixed effects model, controlling for both country-specific characteristics (like geography, health infrastructure, or culture) and time-specific shocks (like global medical advances or economic downturns).

```{r}
library(gapminder)

# Rename for consistency
df <- gapminder %>%
  rename(country = country, year = year,
         life_exp = lifeExp,
         gdp_pc = gdpPercap) %>%
  mutate(log_pop = log(pop))

head(df)
```

Our outcome of interest will be life expectancy, and we’ll examine how it is associated with GDP per capita, while controlling for population size.

```{r}
model_gap_FE <- feols(life_exp ~ log(gdp_pc) + log_pop | country, data = df)
model_gap_TWFE <- feols(life_exp ~ log(gdp_pc) + log_pop | country + year, data = df)


summary(model_gap_FE)
summary(model_gap_TWFE)
```

Let’s compare the results from the one-way fixed effects model (country only) and the two-way fixed effects model (country and year).

In the one-way fixed effects model, the estimated effect of *log(gdp_pc)* on *life expectancy* is 4.48, while in the two-way fixed effects model, the estimate drops to 2.98. Similarly, the effect of *log_pop* decreases from 11.96 to 8.32. These differences suggest that once we control for year-specific shocks -- such as global medical advances, international development programs, or major world events -- the explanatory power of GDP and population size becomes more conservative. That is, GDP still has a positive association with life expectancy, but the effect is smaller once we account for trends that influence all countries in a given year.

We also see changes in model fit statistics. The RMSE (Root Mean Squared Error), which tells us the average prediction error in the units of life expectancy, drops slightly from 3.09 to 2.97, indicating that the two-way fixed effects model makes slightly more accurate predictions overall. However, the within R² decreases dramatically from 0.78 to 0.19. This may seem surprising, but it’s expected. When we include year fixed effects, we absorb more variation from the outcome variable (life expectancy), leaving less variation for GDP and population to explain. That doesn’t mean the model is worse -- it just means that more confounding variation has been removed.

## Clustered standard error

By default, when we fit a fixed effects model using `feols()` with multiple fixed effects (e.g., country + year), the standard errors are clustered by the first fixed effect -- in this case, country. This makes sense, as we usually want to account for serial correlation within each unit over time.

If you want to change the clustering variable, you can explicitly specify it using the cluster argument directly in the model:

```{r}
model_twfe_clustered <- feols(life_exp ~ log(gdp_pc) + log_pop | country + year, 
                              cluster = ~year,
                              data = df)
summary(model_twfe_clustered)
```

In the example above, we clustered standard errors by year, which allows for arbitrary correlation of errors across countries within the same year. This is useful for demonstration purposes to show how clustering affects inference. However, in practice, especially when working with panel data, it is more common to cluster by the unit of observation -- in this case, country -- because observations within the same country over time are likely to be correlated. Clustering by country accounts for serial correlation in the residuals and typically produces more conservative standard errors, which helps ensure valid statistical inference.

# Random Effect

The random effects model is an alternative to fixed effects for analyzing panel data. While fixed effects estimate a separate intercept for each unit (e.g., each country), random effects assume that these unit-specific differences are random deviations from a shared average intercept, drawn from a common distribution. This assumption allows random effects models to use both within-unit and between-unit variation, which often makes them more efficient. However, this efficiency comes at a cost: it assumes that the unit-level effects are not correlated with the explanatory variables. If that assumption is violated, the random effects model may produce biased estimates. We'll demonstrate this using the `gapminder` data, then test the assumptions using the Hausman test.

We’ll use the `plm` package to estimate both fixed and random effects models for life expectancy using GDP per capita and population as predictors.

```{r}
# Prepare data as panel
pdata <- pdata.frame(gapminder, index = c("country", "year"))

# Fixed effects (country + year)
fe_model <- plm(lifeExp ~ log(gdpPercap) + log(pop), data = pdata, model = "within", effect = "twoways")

# Random effects
re_model <- plm(lifeExp ~ log(gdpPercap) + log(pop), data = pdata, model = "random")

# Compare results
summary(fe_model)
summary(re_model)
```

From the random effect output, we see that, 74% of the total error variance is due to differences between countries, and 26% is due to variation within countries over time. Unlike the fixed effects model, the random effects model includes an additional line in the output for the intercept: -115.18. This is the grand mean intercept, representing the average baseline level of the outcome across all units before adding unit-specific random deviations. In contrast, fixed effects models don’t estimate a common intercept because each unit has its own.

## Hausman Test: Should We Trust Random Effects?

The Hausman test allows us to formally test whether the random effects model is appropriate. The null hypothesis is that the random effects model is consistent -- in other words, that there is no correlation between the unit effects and the regressors. If the test rejects the null, we should use fixed effects.

```{r}
# Hausman test
hausman_result <- phtest(fe_model, re_model)
hausman_result
```

p-value is smaller than 0.05, so we reject the null , and should use fixed effects (random effects are likely biased). This test helps you decide between fixed and random effects not based on fit alone, but based on the core assumption about unobserved heterogeneity in your panel data.

# Nonlinear Dependent Variable

So far, we’ve worked with linear fixed effects models where the outcome variable is continuous. However, in many real-world applications, outcomes are nonlinear — for example, binary decisions (e.g., adopted a policy or not), counts (e.g., number of events), or ordinal scales. In these cases, we often turn to nonlinear models such as logistic regression or Poisson regression. Fortunately, we can still incorporate fixed effects into these models to control for unobserved, time-invariant characteristics. 

In this example, we’ll use the `Fatalities` dataset from the `AER` package, which contains U.S. state-level panel data from 1982 to 1988. The dataset includes information on state-level beer taxes, seatbelt laws, traffic fatalities, and minimum legal drinking ages. We'll use a binary outcome variable indicating whether the state had adopted a legal drinking age of 21 (drink21) and estimate the effect of beer taxes (while controlling the effects of spirits consumption, average miles per drive, and the percent of young drivers) on that policy using a logistic fixed effects model. This will illustrate how fixed effects can be applied in a nonlinear context and what trade-offs come with it.

```{r}
data(Fatalities, package = "AER")

summary(Fatalities$drinkage)
length(unique(Fatalities$state)) # 48 states

Fatalities$drink21 <- ifelse(Fatalities$drinkage == 21, 1, 0)

head(Fatalities)
```

```{r}
# Fixed effects logit model
fe_logit <- feglm(drink21 ~ beertax + spirits + miles + youngdrivers | state,
                  data = Fatalities,
                  family = binomial())
summary(fe_logit)
```

The original data has 48 states. However, as the note says, 25 fixed-effects (175 observations) removed because of only 0 (or only 1) outcomes. This leaves only 23 states in the analysis. This happens because the logistic fixed effects model can only use units (e.g., states) where there is variation in the binary outcome. In this case, if a state always had a legal drinking age of 21 (i.e., drink21 = 1 for all years) or never had it (drink21 = 0), the model cannot estimate a likelihood contribution for that unit -- so it is dropped from the estimation. This is a known limitation of nonlinear fixed effects models and is especially common in short panels or when the outcome is rare or mostly one-sided.

From the output, we see that *Beer Tax* has a positive effect on the odds of having a drinking age of 21 -- states with higher beer taxes are more likely to have stricter drinking laws, although the result is marginally significant (p ≈ 0.06). 

Now let’s fit the same model using a linear fixed effects approach and compare the results.

```{r}
fe_linear <- feols(drink21 ~ beertax + spirits + miles + youngdrivers | state, data = Fatalities)
summary(fe_linear)
```

When we compare the results of the linear model to the fixed effects logit model, we see that the estimates differ noticeably in both direction and statistical significance. For example, in the linear model, the coefficient for *beertax* is negative and insignificant, while in the logit model, it was positive and marginally significant. Similarly, *spirits consumption* was strongly negative and statistically significant in the logit model, but its effect is much smaller and weaker in the linear model. These discrepancies highlight how the choice of model -- especially whether it accounts for the binary nature of the outcome -- can substantially affect conclusions.

# Mediation analysis in panel data

Mediation analysis helps us understand how a treatment or predictor variable affects an outcome by introducing a third variable -- the mediator -- that transmits the effect. While the `mediation` package in R is commonly used for this purpose, it does not support fixed effects models from packages like `plm` or `fixest`, which are essential for panel data. 

To work around this limitation, we introduce two practical solutions: (1) use `lm()` and manually include unit fixed effects as dummy variables, which allows the `mediate()` function to run properly; or (2) estimate fixed effects models using `plm()` and manually calculate the Average Causal Mediation Effect (ACME) as the product of coefficients a×b, then use bootstrapping to test its significance.

In this tutorial, we use the gapminder dataset as an example. We examine whether the effect of a country’s GDP per capita (log(gdpPercap)) on its life expectancy (lifeExp) is mediated through population size (log(pop)). In other words, we ask: Does economic development affect life expectancy indirectly by changing population levels? 

Solution 1: use `lm()` and add unit dummies

```{r}
df$country <- factor(df$country, levels = unique(df$country))
gapminder$log_gdpPercap <- log(gapminder$gdpPercap)
gapminder$log_pop       <- log(gapminder$pop)


# Step 1: X → M
m1 <- lm(log_pop ~ log_gdpPercap + country, data = gapminder)

# Step 2: X + M → Y
m2 <- lm(lifeExp ~ log_pop + log_gdpPercap + country, data = gapminder)

# Mediation analysis
med <- mediate(m1, m2, treat = "log_gdpPercap", mediator = "log_pop", boot = TRUE)
summary(med)
```


Solution 2: manually calculate ACME and bootstrap 

```{r}
# Prepare data as panel
pdata <- pdata.frame(gapminder, index = c("country", "year"))

# Step 1: X → M
model_x_m <- plm(log(pop) ~ log(gdpPercap), data = pdata, model = "within")

# Step 2: X + M → Y
model_m_y <- plm(lifeExp ~ log(gdpPercap) + log(pop), data = pdata, model = "within")

# Indirect (mediated) effect
acme <- coef(model_x_m)["log(gdpPercap)"] * coef(model_m_y)["log(pop)"]
acme
```

Then, bootstrap it:

```{r}
set.seed(123)
acme_boot <- numeric(500)

for (i in 1:500) {
  boot_data <- gapminder[sample(nrow(gapminder), replace = TRUE), ]
  pdata_boot <- pdata.frame(boot_data, index = c("country", "year"))
  
  a <- coef(plm(log(pop) ~ log(gdpPercap), data = pdata_boot, model = "within"))["log(gdpPercap)"]
  b <- coef(plm(lifeExp ~ log(pop) + log(gdpPercap), data = pdata_boot, model = "within"))["log(pop)"]
  
  acme_boot[i] <- a * b
}

# Get bootstrap CI
quantile(acme_boot, probs = c(0.025, 0.975))
```

We see that for both approaches, ACME equals to 5.292, and it's statistically significant.

# Instrumental Variable in Fixed Effect

When the main independent variable of interest is endogenous -- that is, correlated with unobserved factors in the error term —-- ordinary fixed effects regression can produce biased estimates. Instrumental variable (IV) techniques offer a solution by using a third variable (the instrument) that affects the treatment but is uncorrelated with the outcome except through that treatment. In panel data, we can combine IV methods with fixed effects to control for both time-invariant confounders and endogeneity in the treatment variable. In this section, we'll demonstrate how to implement two-stage least squares (2SLS) estimation with fixed effects using `fixest`.

We use the CigarettesSW dataset from the `AER` package. You can find more information of this dataset in Tutorial 5. Here, we use sales (log(packs)) as a dependent variable, use price as an endogenous variable, and taxes as the instrumental variable. 

```{r}
# Load the data
data("CigarettesSW")
summary(CigarettesSW)

# compute real per capita prices
CigarettesSW$rprice <- with(CigarettesSW, price / cpi)

#  compute the sales tax
CigarettesSW$salestax <- with(CigarettesSW, (taxs - tax) / cpi)

# IV model with state and year fixed effects:
# Endogenous regressor: log(price)
# Instrument: log(income)
cig_fe_iv <- feols(log(packs) ~ 1 | state | log(rprice) ~ salestax, data = CigarettesSW)


# View results
summary(cig_fe_iv)
```

In fixest, the formula for an instrumental variable model with fixed effects is structured in three parts: the first part includes the outcome and any exogenous regressors, the second part specifies the fixed effects, and the third part defines the endogenous regressor and its instrument. For example, in the model `log(packs) ~ 1 | state + year | log(rprice) ~ salestax`, we are modeling the effect of cigarette prices on consumption. The `~ 1` indicates that there are no additional exogenous control variables beyond the instrumented variable. If we wanted to include a control like *income*, we would instead write `log(packs) ~ income`. The `| state + year` portion adds both state and year fixed effects to account for unobserved heterogeneity across states and over time. Finally, the `| log(rprice) ~ salestax` part specifies that `log(rprice)` is endogenous and is being instrumented by salestax. This structure allows us to cleanly estimate causal effects while controlling for both confounding and endogeneity.